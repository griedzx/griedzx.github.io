[{"categories":[],"content":"生物信息软件综合实践实验报告 ","date":"2023-12-24","objectID":"/%E5%9F%BA%E5%9B%A0%E9%A2%84%E6%B5%8B%E5%92%8C%E5%9F%BA%E5%9B%A0%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/:0:0","tags":[],"title":"基因预测和基因结构分析","uri":"/%E5%9F%BA%E5%9B%A0%E9%A2%84%E6%B5%8B%E5%92%8C%E5%9F%BA%E5%9B%A0%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/"},{"categories":[],"content":"实验题目 ：基因预测和基因结构分析 实验日期：2023年12月5日 星期二 实验者：生物信息2102代子希 ","date":"2023-12-24","objectID":"/%E5%9F%BA%E5%9B%A0%E9%A2%84%E6%B5%8B%E5%92%8C%E5%9F%BA%E5%9B%A0%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/:1:0","tags":[],"title":"基因预测和基因结构分析","uri":"/%E5%9F%BA%E5%9B%A0%E9%A2%84%E6%B5%8B%E5%92%8C%E5%9F%BA%E5%9B%A0%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/"},{"categories":[],"content":"实验目的： 1.掌握常用基因从头预测软件的使用和结果解读 2.熟悉文件格式GFF3的基本信息 3.熟悉至少一种基因组浏览器的使用 4.了解基因结构和非编码基因预测等分析 ","date":"2023-12-24","objectID":"/%E5%9F%BA%E5%9B%A0%E9%A2%84%E6%B5%8B%E5%92%8C%E5%9F%BA%E5%9B%A0%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/:2:0","tags":[],"title":"基因预测和基因结构分析","uri":"/%E5%9F%BA%E5%9B%A0%E9%A2%84%E6%B5%8B%E5%92%8C%E5%9F%BA%E5%9B%A0%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/"},{"categories":[],"content":"实验内容： 1.使用软件Prodigal预测大肠杆菌Escherichia coli K12基因组的基因，并对预测结果进行总结 2.至少使用两种基因从头预测软件预测拟南芥基因组（部分序列）的基因，并对预测结果进行总结和差异比较。 3.使用IGV查看拟南芥重要基因的注释结果 ","date":"2023-12-24","objectID":"/%E5%9F%BA%E5%9B%A0%E9%A2%84%E6%B5%8B%E5%92%8C%E5%9F%BA%E5%9B%A0%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/:3:0","tags":[],"title":"基因预测和基因结构分析","uri":"/%E5%9F%BA%E5%9B%A0%E9%A2%84%E6%B5%8B%E5%92%8C%E5%9F%BA%E5%9B%A0%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/"},{"categories":[],"content":"实验流程和结果 问题1 1.使用Prodigal对组装的大肠杆菌的序列（其中1Mb序列，已提供，见文件ecoli.hifi.fa）进行基因预测，统计预测得到的基因的数量 步骤1：使用prodigal命令 mkdir prodigal cd prodigal prodigal -a ref.pep -d ref.cds -f gff -g 11 -o ref.gff -p single -s ref.stat -i ../../data/ch06/ecoli.hifi.fa \u0026 \u003eprodigal.log \u0026 ref.cds 输出的预测基因的序列文件 ref.gff 输出的基因的位置信息gff文件 ref.pep 输出的预测序列的氨基酸文件 ","date":"2023-12-24","objectID":"/%E5%9F%BA%E5%9B%A0%E9%A2%84%E6%B5%8B%E5%92%8C%E5%9F%BA%E5%9B%A0%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/:4:0","tags":[],"title":"基因预测和基因结构分析","uri":"/%E5%9F%BA%E5%9B%A0%E9%A2%84%E6%B5%8B%E5%92%8C%E5%9F%BA%E5%9B%A0%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/"},{"categories":[],"content":"prodigal文件夹下结果 步骤2：统计预测得到的基因的数量 ①使用awk命令对gff文件进行统计 awk '/^#/ {next} {if ($3 == \"CDS\") count++} END {print count}' ref.gff ②使用grep命令对ref.cds文件进行统计 grep -c \"\u003e\" ref.cds 问题2 2.从给定的拟南芥基因组（TAIR10版本）的某段序列（二号染色体7.5-8.5Mb,文件名：Ath.1mb.fa），完成以下任务： 使用GenScan、Augustus、GlimmerHMM等软件（至少两种软件）预测该序列所包含的蛋白质编码基因。统计不同软件组装得到的基因和外显子（exon）的数量，并选用适当的图表（如直方图）将统计结果进行展示。 从TAIR10网站下载该区间的基因注释信息（已下载到服务器，见文件tair10.ch2_7.5-8.5Mb.genes.gff3），作为标准参考集，试评估第1）题中使用的不同软件预测结果的准确率和召回率等。（可以考虑从基因、exon、CDS等水平上进行比较，比如：对于某个基因，augustus预测的跟tair10的基因重叠区域超过各自注释区间的90%，则认为两者一致，其他exon、CDS的比较，可采用相同标准） 试列举1-2个基因在不同软件和TAIR10中的注释差异情况（结合IGV展示不同软件的注释结果）。可参考的基因：WUS、PHYTOCHROMEB 问题2.1 步骤1：使用Augustus预测 对需要使用的数据创建软连接，使用Augustus预测 cd augustus ln -sf /home/uu02/data/ch06/Ath.1mb.fa ./ augustus --species=arabidopsis Ath.1mb.fa 1\u003eaugustus.out 2\u003elog.txt \u0026 步骤2：对组装结果augustus.out统计得到基因和外显子的数量 Augusuts预测结束后得到了 augustus.out文件，这个文件本质是一个gff格式的文件，文件前半部分是一些 #开头的注释 # 统计基因的数量 gene_count=$(awk -F '\\t' '$3==\"gene\"' augustus.out | wc -l) # 统计外显子的数量 exon_count=$(awk -F '\\t' '$3==\"exon\"' augustus.out | wc -l) # 打印结果 echo \"基因的数量: $gene_count\" echo \"外显子的数量: $exon_count\" **步骤3：**使用GlimmerHMM预测 对需要使用的数据创建软连接，使用GlimmerHMM预测 cd glimmerhmm ln -sf /home/uu02/data/ch06/Ath.1mb.fa ./ glimmerhmm Ath.1mb.fa -d /home/uu02/software/07_GlimmerHMM/GlimmerHMM/trained_dir/arabidopsis -g -n 1 1\u003eref.gff 2\u003elog.txt \u0026 **步骤4：**对组装结果ref.gff统计得到基因和外显子的数量 组装结果也是gff文件，观察发现GlimmerHMM 的预测结果将 gene 和 exon 信息写在了 “Note” 属性中,并且 gene 信息在 “mRNA” 类型的行中 # 统计基因的数量 gene_count=$(awk -F '\\t' '$3==\"mRNA\"' ref.gff | wc -l) # 统计外显子的数量 exon_count=$(awk -F '\\t' '$9 ~ /exon/' ref.gff | wc -l) # 打印结果 echo \"基因的数量: $gene_count\" echo \"外显子的数量: $exon_count\" **步骤5：**选用适当的图表（如直方图）将统计结果进行展示 import matplotlib.pyplot as plt import numpy as np # 设置gene和extron的count counts = {'augustus': {'gene': 228, 'extron': 1360}, 'glimmerHMM': {'gene': 234, 'extron': 1245}} # 创建堆叠的直方图 labels = list(counts.keys()) gene_counts = [counts[label]['gene'] for label in labels] exon_counts = [counts[label]['extron'] for label in labels] x = np.arange(len(labels)) # the label locations width = 0.35 # the width of the bars fig, ax = plt.subplots() rects1 = ax.bar(x - width/2, gene_counts, width, label='gene') rects2 = ax.bar(x + width/2, exon_counts, width, label='extron') #加上具体的数值 for rect in rects1: height = rect.get_height() ax.annotate('{}'.format(height), xy=(rect.get_x()+rect.get_width()/2, height), xytext=(0,3), # 3 points vertical offset textcoords=\"offset points\", ha='center', va='bottom') for rect in rects2: height = rect.get_height() ax.annotate('{}'.format(height), xy=(rect.get_x()+rect.get_width()/2, height), xytext=(0,3), # 3 points vertical offset textcoords=\"offset points\", ha='center', va='bottom') ax.set_ylabel('count') ax.set_title('gene \u0026 extron count') ax.set_xticks(x) ax.set_xticklabels(labels) #图例放在表格外面 ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.) fig.tight_layout() plt.show() ","date":"2023-12-24","objectID":"/%E5%9F%BA%E5%9B%A0%E9%A2%84%E6%B5%8B%E5%92%8C%E5%9F%BA%E5%9B%A0%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/:4:1","tags":[],"title":"基因预测和基因结构分析","uri":"/%E5%9F%BA%E5%9B%A0%E9%A2%84%E6%B5%8B%E5%92%8C%E5%9F%BA%E5%9B%A0%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/"},{"categories":[],"content":"augustus文件夹下结果 部分预测结果 ","date":"2023-12-24","objectID":"/%E5%9F%BA%E5%9B%A0%E9%A2%84%E6%B5%8B%E5%92%8C%E5%9F%BA%E5%9B%A0%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/:4:2","tags":[],"title":"基因预测和基因结构分析","uri":"/%E5%9F%BA%E5%9B%A0%E9%A2%84%E6%B5%8B%E5%92%8C%E5%9F%BA%E5%9B%A0%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/"},{"categories":[],"content":"prodigal文件夹下结果 部分预测结果 问题2.2 不同软件预测结果的准确率和召回率 **步骤1：**使用bedtools intersectbed模块获取重叠部分符合要求的结果 -a -b 指定输入文件 -f 0.9 指定重叠部分最少所占比列 -r 指定重叠部分所占比例在 a 与 b中同时满足 \u003e 0.9 #!/bin/bash augustus='/home/uu02/02_dzx/augustus/augustus.out' glimmerHMM='/home/uu02/02_dzx/glimmerhmm/ref.gff' ref_data='/home/uu02/data/ch06/tair10.ch2_7.5-8.5Mb.genes.gff3' for file in $augustus $glimmerHMM do dir=$(basename $(dirname $file)) intersectBed -a $ref_data -b $file -f 0.9 -r -wao \u003e $dir.intersect done 步骤2： 文件导入本地，用python统计召回率 ：实际为正的样本中被预测为正样本的概率 召回率=TP/(TP+FN) 实际为正的样本数为 ref_data 参考数据中注释为gene / exon的行 实际为正 统计为真的样本，根据不同软件预测结果格式筛选 augustus: gene: data[(data[11] == 'gene') \u0026 (data[2] == 'gene')] exon: (data[11] == 'exon') \u0026 (data[2] == 'exon')] gil mmerhmm: gene: data[(data[11] == 'mRNA') \u0026 (data[2] == 'gene')] exon: data[(data[2] == 'exon') \u0026 (data[17].str.contains('exon'))] import os import pandas as pd #分别从gene、exon水平通过召回率评估不同软件预测结果 file = ['F:/生物信息软件综合实践/05_data/augustus.intersect', 'F:/生物信息软件综合实践/05_data/glimmerhmm.intersect'] ref_data = pd.read_csv('F:/生物信息软件综合实践/05_data/tair10.ch2_7.5-8.5Mb.genes.gff3', sep='\\t', header=None) ref_data_gene = ref_data[ref_data[2] == 'gene'] ref_data_exon = ref_data[ref_data[2] == 'exon'] for f in file: data = pd.read_csv(f, sep='\\t', header=None) software = os.path.basename(f).split('.')[0] #gene g_p_e = len(ref_data_gene) e_p_e = len(ref_data_exon) if software == 'augustus': g_tp = len(data[(data[11] == 'gene') \u0026 (data[2] == 'gene')]) g_recall = g_tp / g_p_e e_tp = len(data[(data[11] == 'exon') \u0026 (data[2] == 'exon')]) e_recall = e_tp / e_p_e print('augustus gene recall: %s, and turn to percentage: %s %%' % (g_recall, format(g_recall*100, '.2f'))) print('augustus exon recall: %s, and turn to percentage: %s %%' % (e_recall, format(e_recall*100, '.2f'))) #转换成百分比 elif software == 'glimmerhmm': g_tp = len(data[(data[11] == 'mRNA') \u0026 (data[2] == 'gene')]) g_recall = g_tp / g_p_e e_tp = len(data[(data[2] == 'exon') \u0026 (data[17].str.contains('exon'))]) e_recall = e_tp / e_p_e print('glimmerhmm gene recall: %s, and turn to percentage: %s %%' % (g_recall, format(g_recall*100, '.2f'))) print('glimmerhmm exon recall: %s, and turn to percentage: %s %%' % (e_recall, format(e_recall*100, '.2f'))) recall(召回率) gene exon glimmerhmm 12.75% 58.35% augustus 46.61% 68.29% 问题2.3 列举1-2个基因在不同软件和TAIR10中的注释差异情况（结合IGV展示不同软件的注释结果）。可参考的基因：WUS、PHYTOCHROMEB ","date":"2023-12-24","objectID":"/%E5%9F%BA%E5%9B%A0%E9%A2%84%E6%B5%8B%E5%92%8C%E5%9F%BA%E5%9B%A0%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/:4:3","tags":[],"title":"基因预测和基因结构分析","uri":"/%E5%9F%BA%E5%9B%A0%E9%A2%84%E6%B5%8B%E5%92%8C%E5%9F%BA%E5%9B%A0%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/"},{"categories":[],"content":"思考与讨论 1.原核生物的基因结构（组成单元、长度、GC含量等）和真核生物的基因结构有哪些差异？（结合大肠杆菌和拟南芥的注释进行分析讨论） 2.不如软件的基因预测结果，有哪些差异？为什么会有这些差异？相比于标准集，哪个软件的预测结果可能相对最好？试结合算法原理，进行讨论 1.原核生物和真核生物的基因结构差异： 原核生物（以大肠杆菌为例），原核生物基因没有内含子,一个基因对应一个连续的mRNA和蛋白质，大肠杆菌基因主要由连续的开放阅读框（ORF）组成，其中包含了编码蛋白质的基因。这些基因通常没有被包裹在真正的细胞核中，而是在细胞质中存在。原核生物基因整体较短,大多数大肠杆菌基因长度小于1000bp，典型的蛋白编码基因长度约为几百到几千个碱基对，原核生物基因前的启动子区域保守,存在信号序列如-10和-35元件 真核生物（以拟南芥为例），真核生物基因由外显子和内含子组成，外显子为编码蛋白质的区域，而内含子则是非编码序列。这些基因通常位于真正的细胞核中，即真核生物基因含有内含子,需要剪接处理长度：。真核生物基因通常较长，其中包含有复杂的调控元件和结构。蛋白编码基因的长度可能达到数千到数万个碱基对，拟南芥等真核生物基因往往很长,部分基因可达几十万bp。拟南芥等高等真核生物基因区GC含量差异较大。真核生物启动子区域结构较复杂,需多个转录因子互作才能启动转录，真核生物同属基因序列保守性差异大,难以仅依靠序列相关性预测基因 2.基因预测软件结果与实际差异的原因以及算法比较： 算法原理:augustus使用生成式隐马尔可夫模型,genscan和glimmerhmm使用隐马尔可夫模型 预测内容:augustus可以预测外显子-内含子结构,genscan和glimmerhmm仅预测外显子 因此: augustus利用了更丰富的外部信息,理论上预测精度应最高 genscan和glimmerhmm仅依靠序列本身,难免会漏预测真实基因或者错误预测假基因 对于拟南芥这类有丰富注释的数据,以augustus训练得到的模型进行预测效果应最好 对于基因组注释不全的物种,三者效果相对,Glimmerhmm可能效果最好 从本次实验计算的召回率以及上述分析，总体来说,利用外部信息(如注释)训练模型进行预测的augustus,在条件允许的情况下,它的预测结果可靠性应最高。 ","date":"2023-12-24","objectID":"/%E5%9F%BA%E5%9B%A0%E9%A2%84%E6%B5%8B%E5%92%8C%E5%9F%BA%E5%9B%A0%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/:5:0","tags":[],"title":"基因预测和基因结构分析","uri":"/%E5%9F%BA%E5%9B%A0%E9%A2%84%E6%B5%8B%E5%92%8C%E5%9F%BA%E5%9B%A0%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/"},{"categories":[],"content":"mamba安装 推荐安装方式 curl -L -O \"https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-$(uname)-$(uname -m).sh\" bash Miniforge3-$(uname)-$(uname -m).sh curl -L -O \"https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-$(uname)-$(uname -m).sh\"：这条命令使用 curl 工具从 GitHub 上下载 Miniforge 的最新版本。-L 参数让 curl 能够处理重定向，-O 参数让 curl 使用 URL 的文件名保存文件。$(uname) 和 $(uname -m) 是 shell 命令，它们分别返回操作系统的名称和机器硬件名称（例如，Linux x86_64），这样可以下载适合当前系统的 Miniforge 版本。 bash Miniforge3-$(uname)-$(uname -m).sh：这条命令使用 bash shell 执行下载的 Miniforge 安装脚本。 ","date":"2023-12-07","objectID":"/mamba/:0:0","tags":[],"title":"Mamba","uri":"/mamba/"},{"categories":[],"content":"首页 | SakuraFrp 帮助文档 (natfrp.com) ","date":"2023-11-29","objectID":"/sakurafrp/:0:0","tags":[],"title":"SakuraFrp","uri":"/sakurafrp/"},{"categories":["Deep Learning from Scratch 学习笔记"],"content":"感知机 x是输入信号，y是输出信号，w(weight)是权重 输入信号分别乘以固定的权重(w*x)，传输至下一个神经元，超过某一个阈值(theta)时输出1，表示“神经元被激活” 通过改变感知机的参数（w,theta）,也就是权重和阈值，相同构造的感知机可以表示与门、与非门、或门 与非门真值表 与门正值表 或门真值表 ","date":"2023-11-28","objectID":"/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01/:1:0","tags":[],"title":"学习记录(1)","uri":"/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01/"},{"categories":["Deep Learning from Scratch 学习笔记"],"content":"简单实现 #与门 def AND(x1, x2): w1, w2, theta = 0.5, 0.5, 0.7 tmp = w1*x1 + w2*x2 if tmp \u003c= theta: return 0 elif tmp \u003e theta: return 1 与非门的参数可以直接时 与门参数值的符号取反 ","date":"2023-11-28","objectID":"/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01/:1:1","tags":[],"title":"学习记录(1)","uri":"/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01/"},{"categories":["Deep Learning from Scratch 学习笔记"],"content":"导入权重与偏置 将阈值（theta）换成-b,公式变形，也就是上式，同样可以表达感知机 感知机会计算输入信号和权重的乘积，然后加上偏置，通过与0大小判断来决定是否激活神经元 numpy实现感知机 import numpy as np def AND(x1, x2): x = np.array([0,1]) #input w = np.array([0.5, 0.5]) #weight b = -0.7 #bias tmp = np.sum(w*x) + b if tmp \u003c= 0: return 0 else: return 1 #直接修改w b可以分别实现与非门以及或门 w权重用于控制输入信号重要性占比，(-theta)偏置(b)用于调整神经元被激活的容易程度 ","date":"2023-11-28","objectID":"/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01/:1:2","tags":[],"title":"学习记录(1)","uri":"/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01/"},{"categories":["Deep Learning from Scratch 学习笔记"],"content":"局限性 单层感知机无法直接实现异或门（仅有一者为整输出1）（异或：拒绝其他） 感知机可视化 上述构造的感知机，在坐标系中是通过一条直线划分成符合要求的两块空间，（以真值表中四个点为例）异或门只能用曲线分开 也就是单层感知机无法分离非线性空间 ","date":"2023-11-28","objectID":"/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01/:1:3","tags":[],"title":"学习记录(1)","uri":"/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01/"},{"categories":["Deep Learning from Scratch 学习笔记"],"content":"多层感知机 python实现异或门 def AND(x1, x2): x = np.array([x1,x2]) #input w = np.array([0.5, 0.5]) #weight b = -0.7 #bias tmp = np.sum(w*x) + b if tmp \u003c= 0: return 0 else: return 1 def NAND(x1, x2): x = np.array([x1,x2]) #input w = np.array([-0.5, -0.5]) #weight b = 0.7 #bias tmp = np.sum(w*x) + b if tmp \u003c= 0: return 0 else: return 1 def OR(x1, x2): x = np.array([x1,x2]) #input w = np.array([0.5, 0.5]) #weight b = -0.2 #bias tmp = np.sum(w*x) + b if tmp \u003c= 0: return 0 else: return 1 def XOR(x1, x2): s1 = NAND(x1, x2) s2 = OR(x1, x2) return AND(s1, s2) print (\"0,0\", XOR(0,0)) print (\"1,0\", XOR(1,0)) print (\"0,1\", XOR(0,1)) print (\"1,1\", XOR(1,1)) 0,0 0 1,0 1 0,1 1 1,1 0 ","date":"2023-11-28","objectID":"/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01/:1:4","tags":[],"title":"学习记录(1)","uri":"/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01/"},{"categories":["Deep Learning from Scratch 学习笔记"],"content":"与非门至计算机 ","date":"2023-11-28","objectID":"/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01/:1:5","tags":[],"title":"学习记录(1)","uri":"/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01/"},{"categories":["Deep Learning from Scratch 学习笔记"],"content":"神经网络 ","date":"2023-11-28","objectID":"/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01/:2:0","tags":[],"title":"学习记录(1)","uri":"/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01/"},{"categories":["vscode配置"],"content":"通过vscode的remote-ssh插件可以在vscode上远程登陆服务器，登录和打开工作文件夹时都需要输入密码，可以通过配置ssh免密登录，使登录和使用更加丝滑 ","date":"2023-11-20","objectID":"/vscode%E5%AF%86%E9%92%A5%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5/:0:0","tags":[],"title":"Vscode密钥远程连接","uri":"/vscode%E5%AF%86%E9%92%A5%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5/"},{"categories":["vscode配置"],"content":"必要软件安装 ssh-keygen 和 ssh-copy-id 安装，window电脑powershell中这两个命令已内置 ","date":"2023-11-20","objectID":"/vscode%E5%AF%86%E9%92%A5%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5/:1:0","tags":[],"title":"Vscode密钥远程连接","uri":"/vscode%E5%AF%86%E9%92%A5%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5/"},{"categories":["vscode配置"],"content":"ssh-keygen配置密钥对 配置密钥 PS C:\\Users\\griedzx\u003e ssh-keygen Generating public/private rsa key pair. Enter file in which to save the key (C:\\Users\\griedzx/.ssh/id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in C:\\Users\\griedzx/.ssh/id_rsa Your public key has been saved in C:\\Users\\griedzx/.ssh/id_rsa.pub The key fingerprint is: SHA256:sYURFrXR+/Xffdy+HmOSu1yxPCH8WbXcoKNvSZF4RDQ griedzx@dzx_pc The key's randomart image is: +---[RSA 3072]----+ | =+o+E | | . o oo. | | o oo o. .| | +. *...=| | S .o= *+| | ...* B| | .. + %=| | .+ = @| | ..+o++| +----[SHA256]-----+ 注意 Enter passphrase (empty for no passphrase): 不输入密码，直接回车继续，否则之前对应输入服务器用户密码的地方变成了密钥对的密码 ssh-keygen常用参数 ssh-keygen -t: 密钥类型, 可以选择 dsa | ecdsa | ed25519 | rsa; -f: 密钥目录位置, 默认为当前用户home路径下的.ssh隐藏目录, 也就是~/.ssh/, 同时默认密钥文件名以id_rsa开头. 如果是root用户, 则在/root/.ssh/id_rsa, 若为其他用户, 则在/home/username/.ssh/id_rsa; -C: 指定此密钥的备注信息, 需要配置多个免密登录时, 建议携带; -N: 指定此密钥对的密码, 如果指定此参数, 则命令执行过程中就不会出现交互确认密码的信息了. 设定目录下会出现密钥对文件：id_rsa.pub是公钥 id_rsa是私钥 ","date":"2023-11-20","objectID":"/vscode%E5%AF%86%E9%92%A5%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5/:2:0","tags":[],"title":"Vscode密钥远程连接","uri":"/vscode%E5%AF%86%E9%92%A5%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5/"},{"categories":["vscode配置"],"content":"公钥传输至服务器 公钥放server(远程主机)上，私钥放本机上 ","date":"2023-11-20","objectID":"/vscode%E5%AF%86%E9%92%A5%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5/:3:0","tags":[],"title":"Vscode密钥远程连接","uri":"/vscode%E5%AF%86%E9%92%A5%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5/"},{"categories":["vscode配置"],"content":"代码传输 公钥配置至服务器上（Window -\u003e Linux） $USER_AT_HOST = \"yh@760755rf68.imdo.co\" #id@ip $PUBKEYPATH = \"$HOME/.ssh/id_rsa.pub\" $pubKey = (Get-Content \"$PUBKEYPATH\"|Out-string); ssh -p 37763 \"$USER_AT_HOST\" \"echo '${pubKey}' \u003e\u003e ~/.ssh/authorized_keys\" ","date":"2023-11-20","objectID":"/vscode%E5%AF%86%E9%92%A5%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5/:3:1","tags":[],"title":"Vscode密钥远程连接","uri":"/vscode%E5%AF%86%E9%92%A5%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5/"},{"categories":["vscode配置"],"content":"简单粗暴的方法 建议直接cat 本地的id_rsa.pub PS C:\\Users\\griedzx\\.ssh\u003e cat id_rsa.pub 然后复制内容到服务器的~/.ssh/authorized_keys中新增一行 #服务器端 (base) yh@localhost 21:21:38 ~/.ssh $ vim authorized_keys ","date":"2023-11-20","objectID":"/vscode%E5%AF%86%E9%92%A5%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5/:3:2","tags":[],"title":"Vscode密钥远程连接","uri":"/vscode%E5%AF%86%E9%92%A5%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5/"},{"categories":["vscode配置"],"content":"修改$home/.ssh/config 修改.ssh/config文件：加入IdentityFile的路径（也就是私钥在本机的所在位置） Host yh_xw HostName 760755rf68.imdo.co Port 37763 User yh IdentityFile \"C:\\Users\\griedzx\\.ssh\\id_rsa\" vscode登录server就不用输入密码了 ","date":"2023-11-20","objectID":"/vscode%E5%AF%86%E9%92%A5%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5/:4:0","tags":[],"title":"Vscode密钥远程连接","uri":"/vscode%E5%AF%86%E9%92%A5%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5/"},{"categories":[],"content":"2023.11.10 好多事压得喘不过气，以致于感叹时间不够用，希望一个良好的睡眠可以解决一些些压力🙏 ","date":"2023-11-10","objectID":"/dairy/:0:0","tags":[],"title":"Dairy","uri":"/dairy/"},{"categories":["本科项目育人"],"content":"项目介绍 植物的自交不亲和性有许多原因，其中本项目所关注的异型花柱是其中之一，这种花的多态性结构至少出现在28个被子植物科中，准备搜集研究其中公共数据库中已有相关植物的基因组，对这些植物的基因组进行比较分析、共线性分析等，其中特别关注比较s位点上的超基因，去研究这些植物自交不亲和的差异以及相似性，帮助理解这些植物基因组的演化关系，以及s位点上的超基因的演化动态。 基因组比较 ：接下来，可以使用synteny、mcscan、mummer等软件工具，对这些植物的基因组进行比较分析。可以通过比较s位点上的超基因，来研究这些植物自交不亲和性的差异和相似性。 共线性分析 ：在基因组比较的基础上，还可以进行共线性分析。这将帮助你理解这些植物基因组的演化关系，以及s位点上超基因的演化动态。 ","date":"2023-11-03","objectID":"/%E9%A1%B9%E7%9B%AE%E8%82%B2%E4%BA%BA%E5%88%9D%E4%BD%93%E9%AA%8C/:1:0","tags":[],"title":"项目育人初体验","uri":"/%E9%A1%B9%E7%9B%AE%E8%82%B2%E4%BA%BA%E5%88%9D%E4%BD%93%E9%AA%8C/"},{"categories":["本科项目育人"],"content":"自交不亲和性（SI）Self-incompatibility 概念 指具有 完全花并可以形成正常雌、雄配子，但缺乏自花授粉结实能力的一种自交不育性。 完全花概述图 陆地生物占地球生物总数的85%，其多样性与被子植物的起源和扩张密切相关。被子植物约有20多万种，是植物界最大的类群，但其形成和扩张的原因仍为未解之谜。现存被子植物中，约40%具有自交不亲和性 (Self-incompatibility, SI)。SI是一种正常可育的雌雄同花被子植物自花授粉后不能产生合子的现象，对于促进其异交并增加其多样性至关重要。 ","date":"2023-11-03","objectID":"/%E9%A1%B9%E7%9B%AE%E8%82%B2%E4%BA%BA%E5%88%9D%E4%BD%93%E9%AA%8C/:1:1","tags":[],"title":"项目育人初体验","uri":"/%E9%A1%B9%E7%9B%AE%E8%82%B2%E4%BA%BA%E5%88%9D%E4%BD%93%E9%AA%8C/"},{"categories":["本科项目育人"],"content":"异型花柱(heterostyly) 根据推文：武汉植物园在植物异型花柱分子遗传调控机制研究中取得新进展所说 具有异型花柱的物种通常同时具有自交不亲和机制 异型花柱在被子植物中广泛分布，已在28个科中被报道 异型花柱在遗传上是由S位点（一个超基因，由多个紧密连锁的基因组成，这些基因分别控制花柱长度或雄蕊高度等特征）决定的 概念 异型花柱是著名的花的多态性现象之一，表现为雌蕊与雄蕊的高度交互匹配，即交互式雌雄异位。雌蕊（花的雌性部分）和雄蕊（花的雄性部分）的长度和位置能够精确地匹配，以便在传粉过程中，雄蕊能够将花粉准确地传递到雌蕊上。 插一个很有意思的科普推文 上下三百年：“花柱异长”是怎么被发现的？| 果壳 科技有意思 (guokr.com) 从这篇推文的描述中看，似乎这个雌蕊与雄蕊的高度交互匹配，是长柱花的雌蕊和短柱花的雄蕊（或者相反）交互匹配，这样也导致花粉不同类型之间传播，而相同类型则断绝了传播，从而既不浪费又阻止了近亲繁殖。 有效传粉者长期缺乏时异型花柱植物可能的演化趋势。 由于基因突变以及生物因子（如传粉者）和非生物因子的共同作用，有时异型花柱多态性结构难以稳定维持，在群体间和群体内产生极大变异，最终促进植物交配系统的多样性演化,如上图所示。 趋同进化 研究发现，植物花柱异长独立演化超过了20次，这个复杂的多态现象已经成为了趋同进化的经典案例。 对于趋同进化，最符合我们常识的是，植物界中，很多亲缘关系甚远的物种会在自然选择作用下表现出趋同进化现象，例如生活在干旱沙漠环境中的植物往往叶片退化成针状，高山植物大多矮化成垫状等。 在异型花柱这个性状中，自然环境带来的压力（想要成功繁殖，不同花型的植株之间需要匹配的花型以接收相同高度的繁殖器官之间的花粉流），使得一种花型的雄性和互补花型的雌性适合度得到增强，这样一来，选择压力会使得花柱异长的植物性别专化。 我们要研究是在目前发现的异型花柱的形态趋同进化的背后是否隐藏着分子水平的趋同进化。 ","date":"2023-11-03","objectID":"/%E9%A1%B9%E7%9B%AE%E8%82%B2%E4%BA%BA%E5%88%9D%E4%BD%93%E9%AA%8C/:1:2","tags":[],"title":"项目育人初体验","uri":"/%E9%A1%B9%E7%9B%AE%E8%82%B2%E4%BA%BA%E5%88%9D%E4%BD%93%E9%AA%8C/"},{"categories":["本科项目育人"],"content":"S位点（S-locus） 自交不亲和这一复杂性状由一个高多态性超基因S位点控制。 概念 s位点是一种遗传位点，通常由单一复等位且包含紧密连锁的雌性和雄性S基因的S位点控制。 其中，1类S位点常包含一个S-核酸酶和多个SLF，分别编码雌性和雄性自交不亲和决定因子 雌性S基因编码一个T2类核酸酶即S-核酸酶 雄性S基因则编码多个C端为FBK或FBA结构域的F-box蛋白SLF 异交授粉时，由于多个SLF可协同识别并解除异己S-核酸酶的细胞毒性，因而产生异交亲和反应；而在自交授粉时，自己S-核酸酶的毒性由于无法被抑制，最终产生自交不亲和反应。 即我自己的柱头不承认我自己的花粉，落上来也不理睬它，不允许它正常发育 超基因是由多个基因组成的一个遗传单元，这些基因通常紧密连锁在一起，以便在遗传上一起传递。异型花柱是一种由超基因控制的花形态结构的多样性， ","date":"2023-11-03","objectID":"/%E9%A1%B9%E7%9B%AE%E8%82%B2%E4%BA%BA%E5%88%9D%E4%BD%93%E9%AA%8C/:1:3","tags":[],"title":"项目育人初体验","uri":"/%E9%A1%B9%E7%9B%AE%E8%82%B2%E4%BA%BA%E5%88%9D%E4%BD%93%E9%AA%8C/"},{"categories":["本科项目育人"],"content":"武汉植物园在植物异型花柱分子遗传调控机制研究中取得新进展 推文解读 异型花柱的研究对象 ：水生植物 金银莲花 （Nymphoides indica），具有长、短柱花两种形态，由S位点决定。 基因组测序和关联分析 ：构建了高质量的 单倍型基因组 ，并通过全基因组关联分析发现了控制金银莲花异型花柱的 S位点超基因 ，鉴定并解析了金银莲花中S位点超基因的演化和功能，发现了三个S位点候选基因 - NinBAS1、NinKHZ2、NinS1。 S位点基因的功能和演化 ：研究团队探讨了S位点基因及其调控网络的潜在功能，以及转座元件和逐步基因复制对异型花柱超基因演化可能起到的作用。研究结果表明，油菜素内酯和PIF分子调控网络在金银莲花异型花柱的发育过程中具有重要的作用，为分子层面上异型花柱的趋同演化提供了进一步的证据。 ","date":"2023-11-03","objectID":"/%E9%A1%B9%E7%9B%AE%E8%82%B2%E4%BA%BA%E5%88%9D%E4%BD%93%E9%AA%8C/:2:0","tags":[],"title":"项目育人初体验","uri":"/%E9%A1%B9%E7%9B%AE%E8%82%B2%E4%BA%BA%E5%88%9D%E4%BD%93%E9%AA%8C/"},{"categories":["本科项目育人"],"content":"花柱异型的科名录 Ensembl Plants Ensembl植物数据库 花柱异型研究进展.pdf (book118.com) 在这篇2010年有关异型花柱的中文综述中提及为30多种 Comparative Genomics Elucidates the Origin of a Supergene Controlling Floral Heteromorphism - PubMed (nih.gov) A classic example of supergene is the S locus controlling heterostyly, a floral heteromorphism occurring in 28 angiosperm families. In Primula, heterostyly is characterized by the cooccurrence of two complementary, self-incompatible floral morphs and is controlled by five genes clustered in the hemizygous, ca. 300-kb S locus. 在这篇22年文章中 ‘A most complex marriage arrangement’: recent advances on heterostyly and unresolved questions (wiley.com) 针对下载的基因组 通过GFF/GTF文件评估基因组注释完整性 GFF（Generic Feature Format）, 描述了基因组上各种特征的区间信息，包括染色体，基因，转录本等。GFF文件 ‘\\t’分隔的纯文本文件。 检查GFF文件，若显示有exon和CDS信息，则基因组注释相对完全，可用于分析。如果既没有exon信息，也没有CDS信息，则基因组注释信息缺失，需要等注释信息完善后才可以用于有参转录组分析的参考基因组。 ","date":"2023-11-03","objectID":"/%E9%A1%B9%E7%9B%AE%E8%82%B2%E4%BA%BA%E5%88%9D%E4%BD%93%E9%AA%8C/:3:0","tags":[],"title":"项目育人初体验","uri":"/%E9%A1%B9%E7%9B%AE%E8%82%B2%E4%BA%BA%E5%88%9D%E4%BD%93%E9%AA%8C/"},{"categories":["本科项目育人"],"content":"参考 自交不亲和性_百度百科 (baidu.com) 被子植物自交不亲和性起源、丢失和重获的高度动态进化机制 (baidu.com) 华南植物园等在异型花柱植物的交配多样性演化研究中获进展—-中国科学院 (cas.cn) 武汉植物园在植物异型花柱分子遗传调控机制研究中取得新进展 (qq.com) 上下三百年：“花柱异长”是怎么被发现的？| 果壳 科技有意思 (guokr.com) 科学驿站｜最新研究：基因水平的趋同进化推动植物形态上的趋同进化_腾讯新闻 (qq.com) 中科院薛勇彪研究组合作揭示金鱼草基因组S位点超基因的动态演化机制 - 知乎 (zhihu.com) 遗传发育所等揭示被子植物自交不亲和性起源、丢失和重获的高度动态进化机制—-中国科学院 (cas.cn) 花柱异型研究进展.pdf (book118.com) ","date":"2023-11-03","objectID":"/%E9%A1%B9%E7%9B%AE%E8%82%B2%E4%BA%BA%E5%88%9D%E4%BD%93%E9%AA%8C/:4:0","tags":[],"title":"项目育人初体验","uri":"/%E9%A1%B9%E7%9B%AE%E8%82%B2%E4%BA%BA%E5%88%9D%E4%BD%93%E9%AA%8C/"},{"categories":[],"content":"解决github打不开的方法（亲测有效） - 知乎 (zhihu.com) IP/服务器github.com的信息 - 站长工具 (chinaz.com) IP/服务器github.global.ssl.fastly.net的信息 - 站长工具 (chinaz.com) ","date":"2023-10-28","objectID":"/github_network_err/:0:0","tags":[],"title":"Github_network_err","uri":"/github_network_err/"},{"categories":["表观组学"],"content":"使用deeptools的 computeMatrix + (plotHeatmap or plotProfile)可以针对某些特定类型的区域如TTS、TES的指定区域范围进行信号富集程度的可视化 ","date":"2023-10-20","objectID":"/%E7%94%B2%E5%9F%BA%E5%8C%96-%E7%BB%84%E8%9B%8B%E7%99%BD%E6%B5%8B%E5%BA%8Fheatmap-profile%E7%BB%98%E5%88%B6/:0:0","tags":["computeMatrix"],"title":"甲基化+组蛋白测序heatmap+profile绘制","uri":"/%E7%94%B2%E5%9F%BA%E5%8C%96-%E7%BB%84%E8%9B%8B%E7%99%BD%E6%B5%8B%E5%BA%8Fheatmap-profile%E7%BB%98%E5%88%B6/"},{"categories":["表观组学"],"content":"computeMatrix’s parameters computeMatrix提供两个不同参数（parameters）以指定不同的参考系 Commands: scale-regions In the scale-regions mode, all regions in the BED file are stretched or shrunken to the length (in bases) indicated by the user. reference-point Reference-point refers to a position within a BED region (e.g., the starting point). In this mode, only those genomicpositions before (upstream) and/or after (downstream) of the reference point will be plotted. 对于reference-point，只指定一个参考点(TTS,TES,center),因此对于基因组区域文件 \u003cbed file(s)\u003e,不会对不同基因均一化，直接使用指定上游或者下游一段距离 对应scale-region,会均一化基因长度,使得不同基因TSS至TES之间区域长度一致。 --regionBodyLength REGIONBODYLENGTH, -m REGIONBODYLENGTH Distance in bases to which all regions will be fit. (Default: 1000) --binSize BINSIZE, -bs BINSIZE Length, in bases, of the non-overlapping bins for averaging the score over the regions length. (Default: 10) 在众多参数中，computeMatrix通过 regionBodyLength和 binSize来确定将不同基因分成相同分数的bin长度，使得基因长度均一化。 默认参数中 regionBodyLength=1000 binSize=10，因此份数为1000/10=100，也就是将不同的基因统一切成100块，每一块参数对应一段bin内所有信号加和除以bin长度的平均值。 ","date":"2023-10-20","objectID":"/%E7%94%B2%E5%9F%BA%E5%8C%96-%E7%BB%84%E8%9B%8B%E7%99%BD%E6%B5%8B%E5%BA%8Fheatmap-profile%E7%BB%98%E5%88%B6/:1:0","tags":["computeMatrix"],"title":"甲基化+组蛋白测序heatmap+profile绘制","uri":"/%E7%94%B2%E5%9F%BA%E5%8C%96-%E7%BB%84%E8%9B%8B%E7%99%BD%E6%B5%8B%E5%BA%8Fheatmap-profile%E7%BB%98%E5%88%B6/"},{"categories":["表观组学"],"content":"对不同组蛋白_ChIP-seq测序数据画图 针对与不同的目的蛋白结合的 DNA 片段进行测序数据，我们可以一次性输入多个对应的bigwig文件画成一张图。 具体代码: bed=/home/ljx/yuanh/work_data/Ref_genome/220721_Maize_B73_V4/Maize_gene_1-10_chr.bed for org_path in /home/yuanhx/dzx/230612_encher_data/0*; do org=$(basename $org_path | sed 's/^...//') bw_files=\"\" for bw_id in $org_path/result/0*/bam/*bigwig; do bw_files=\"$bw_files $bw_id\" done computeMatrix scale-regions -p 10 \\ -b 2000 -a 2000 \\ -R $bed \\ -S $bw_files \\ --missingDataAsZero \\ --skipZeros -o $org_path/result/matrix_${org}_2K.gz plotHeatmap -m $org_path/result/matrix_${org}_2K.gz \\ -out /home/yuanhx/dzx/230612_encher_data/${org}_Heatmap_2K.png done ","date":"2023-10-20","objectID":"/%E7%94%B2%E5%9F%BA%E5%8C%96-%E7%BB%84%E8%9B%8B%E7%99%BD%E6%B5%8B%E5%BA%8Fheatmap-profile%E7%BB%98%E5%88%B6/:2:0","tags":["computeMatrix"],"title":"甲基化+组蛋白测序heatmap+profile绘制","uri":"/%E7%94%B2%E5%9F%BA%E5%8C%96-%E7%BB%84%E8%9B%8B%E7%99%BD%E6%B5%8B%E5%BA%8Fheatmap-profile%E7%BB%98%E5%88%B6/"},{"categories":["表观组学"],"content":"对甲基化测序数据画图 初始数据处理 $ head -100 output-prefix.bsmap.mkdup_CHG.bedGraph track type=\"bedGraph\" description=\"output-prefix.bsmap.mkdup CHG methylation levels\" 1 1472 1473 100 9 0 1 1474 1475 90 311 34 1 1533 1534 75 6 2 1 1535 1536 69 99 43 1 1562 1563 33 3 6 1 1581 1582 37 3 5 1 1654 1655 50 2 2 1 1712 1713 75 9 3 1 1714 1715 100 3 0 直接使用原始bedGraph数据通过 bedGraphToBigwig 转换成bigwig文件画图，missingdata过多，热图黑色部分贼多 人工分bin，将1号染色体的最开始片段位置初始化0，按照100bp分段，对应的四列数据百分比处理 最后处理后的格式如下： 画图代码： bed=\"/home/ljx/yuanh/work_data/Ref_genome/220721_Maize_B73_V4/Maize_gene_1-10_chr.bed\" for id in /home/yh/dzx/work/231017_methylation/methylation_bigwig_data/*;do org=`echo $id | cut -d '/' -f 8` echo \"org:$org\" bigwig_files=`ls $id/*.bigwig` echo -e \"bigwig_files:\\n$bigwig_files\" computeMatrix scale-regions -p 10 \\ -b 2000 -a 2000 \\ -R $bed \\ -S $bigwig_files \\ --missingDataAsZero \\ --skipZeros -o /home/yh/dzx/work/231017_methylation/matrix/$org/matrix.gz echo \"$org matrix.gz done\" plotHeatmap -m /home/yh/dzx/work/231017_methylation/matrix/$org/matrix.gz \\ -out /home/yh/dzx/work/231017_methylation/plotHeatmap/$org/${org}_Heatmap_2K.pdf echo \"$org heatmap done\" done 甲基化热图 ","date":"2023-10-20","objectID":"/%E7%94%B2%E5%9F%BA%E5%8C%96-%E7%BB%84%E8%9B%8B%E7%99%BD%E6%B5%8B%E5%BA%8Fheatmap-profile%E7%BB%98%E5%88%B6/:3:0","tags":["computeMatrix"],"title":"甲基化+组蛋白测序heatmap+profile绘制","uri":"/%E7%94%B2%E5%9F%BA%E5%8C%96-%E7%BB%84%E8%9B%8B%E7%99%BD%E6%B5%8B%E5%BA%8Fheatmap-profile%E7%BB%98%E5%88%B6/"},{"categories":["表观组学"],"content":"分表达水平高低绘制信号富集谱图 给基因区域bed文件赋值基因表达数据,将表达数据赋值至最后一列 gene_bed \u003c- read.table(\"gene_length.bed\", header = F, sep = \"\\t\", stringsAsFactors = F) exp_data_1 \u003c- read.csv(\"/home/yuanhx/dzx/work_data/exp_data/lai_py_expressed.csv\", header = T) exp_data_2 \u003c- read.csv(\"/home/yuanhx/dzx/work_data/exp_data/yang_ear_tassel.csv\", header = T) gene_bed$V6 \u003c- sub(\"ID=gene:\", \"\", gene_bed$V6) exp_data_1$tracking_id \u003c- as.character(exp_data_1$tracking_id) exp_data_2$tracking_id \u003c- as.character(exp_data_2$tracking_id) orgs \u003c- c(\"ear_1\", \"ear_2\", \"shoot_1\", \"shoot_2\", \"tassel\") for (org in orgs){ for (i in 1:nrow(gene_bed)){ if(org %in% c(\"ear_1\", \"shoot_1\",\"shoot_2\")){ if(gene_bed$V6[i] %in% exp_data_1$tracking_id == F){ gene_bed$V8[i] \u003c- \"not_found\" next } if(org %in% c(\"ear_1\", \"shoot_1\")){ gene_bed$V8[i] \u003c- exp_data_1[which(exp_data_1$tracking_id == gene_bed$V6[i]), paste0(\"average.\",sub(\"..$\",\"\",org))] } else if(org == \"shoot_2\"){ gene_bed$V8[i] \u003c- exp_data_1[which(exp_data_1$tracking_id == gene_bed$V6[i]), paste0(sub(\"..$\",\"\",org),\".average\")] } } else{ if(gene_bed$V6[i] %in% exp_data_2$tracking_id == F){ gene_bed$V8[i] \u003c- \"not_found\" next } if(org == \"ear_2\") org = \"ear\" gene_bed$V8[i] \u003c- exp_data_2[which(exp_data_2$tracking_id == gene_bed$V6[i]), paste0(\"average.\",org)] org = \"ear_2\" } } write.table(gene_bed, file.path(org, paste0(org, \"_gene_exp\",\".bed\")), row.names = F, col.names = F, sep = \"\\t\") } 做实验的提供的表达量数据格式真的是个无敌复杂，而且总是多次用到，应该找个时间优化一下格式 根据表达量切分bed文件 #!/bin/bash data_dir=\"/home/yuanhx/dzx/org_gene_bed/\" for subdir in ear_1 ear_2 shoot_1 shoot_2 tassel; do echo \"处理子目录: $subdir\" cd \"$data_dir$subdir\" gene_exp_file=*gene_exp.bed # 对文件按照表达量排序 sort -k 8,8n $gene_exp_file \u003e sorted_gene_exp.bed split -d -n l/7 sorted_gene_exp.bed split_ for ((i=0; i\u003c7; i++)); do mv \"split_0$i\" \"part$i.bed\" done echo \"处理完成: $gene_exp_file\" cd \"$data_dir\" done 处理后文件存放格式如此 画图 for id in /home/yuanhx/dzx/230612_encher_data/0*/result/0*/bam/*bigwig; do org=$(echo $id | awk -F'/' '{print $6}' | cut -c4-) bed_files=\"\" for bed_id in /home/yuanhx/dzx/org_gene_bed/$org/part*.bed; do bed_files=\"$bed_files $bed_id\" done out_path=$(echo $id | cut -d'/' -f1-8) seq_name=$(basename $id | cut -d'.' -f1) computeMatrix scale-regions -p 11 \\ -b 2000 -a 2000 \\ -R $bed_files \\ -S $id \\ --missingDataAsZero \\ --skipZeros -o $out_path/matrix/${seq_name}_2k.gz plotProfile -m $out_path/matrix/${seq_name}_2k.gz -out $out_path/matrix/${seq_name}_Profile_2K.png done -S bigwig文件 -R bed文件可以分别传入多个 ","date":"2023-10-20","objectID":"/%E7%94%B2%E5%9F%BA%E5%8C%96-%E7%BB%84%E8%9B%8B%E7%99%BD%E6%B5%8B%E5%BA%8Fheatmap-profile%E7%BB%98%E5%88%B6/:4:0","tags":["computeMatrix"],"title":"甲基化+组蛋白测序heatmap+profile绘制","uri":"/%E7%94%B2%E5%9F%BA%E5%8C%96-%E7%BB%84%E8%9B%8B%E7%99%BD%E6%B5%8B%E5%BA%8Fheatmap-profile%E7%BB%98%E5%88%B6/"},{"categories":["生物文本挖掘"],"content":"TF-IDF简要介绍 TF-IDF(term frequency–inverse document frequency)，一种常用于挖掘文章中关键词的加权技术。某个词在文章（一篇文章或者某类文章）中的TF-IDF越大，那么一般而言这个词在这篇文章的重要性会越高 ，可以作为其一个特征 TF-IDF(词频-逆文档频率)=TF * IDF ","date":"2023-10-18","objectID":"/tf-idf/:1:0","tags":[],"title":"TF-IDF","uri":"/tf-idf/"},{"categories":["生物文本挖掘"],"content":"词频（TF） 表示词条（关键字）在文本中出现的频率 ,通常会被归一化(一般是词频除以文章总词数)。 上述没有统一标准化词频，用来展现特定主题文章下特定词语出现的次数。 ","date":"2023-10-18","objectID":"/tf-idf/:1:1","tags":[],"title":"TF-IDF","uri":"/tf-idf/"},{"categories":["生物文本挖掘"],"content":"逆文档频率 (IDF) 某一特定词语的IDF，可以由 总文件数目除以包含该词语的文件的数目 ， 再将得到的商取对数得到 。 ","date":"2023-10-18","objectID":"/tf-idf/:1:2","tags":[],"title":"TF-IDF","uri":"/tf-idf/"},{"categories":["生物文本挖掘"],"content":"TF-IDF计算的伪代码 # 定义文档集合 documents = [...] # 计算词频TF def computeTF(wordDict, doc): tfDict = {} corpusCount = len(doc) for word, count in wordDict.items(): tfDict[word] = count / float(corpusCount) return tfDict # 计算逆文档频率IDF def computeIDF(docList): import math idfDict = {} N = len(docList) idfDict = dict.fromkeys(docList[0].keys(), 0) for doc in docList: for word, val in doc.items(): if val \u003e 0: idfDict[word] += 1 for word, val in idfDict.items(): idfDict[word] = math.log10(N / float(val)) return idfDict # 计算TF-IDF def computeTFIDF(tfBagOfWords, idfs): tfidf = {} for word, val in tfBagOfWords.items(): tfidf[word] = val * idfs[word] return tfidf ","date":"2023-10-18","objectID":"/tf-idf/:2:0","tags":[],"title":"TF-IDF","uri":"/tf-idf/"},{"categories":["生物文本挖掘"],"content":"NLTK实现TF-IDF计算 from nltk.text import TextCollection from nltk.tokenize import word_tokenize #首先，构建语料库corpus sents=['this is sentence one','this is sentence two','this is sentence three'] sents=[word_tokenize(sent) for sent in sents] #对每个句子进行分词 print(sents) #输出分词后的结果 corpus=TextCollection(sents) #构建语料库 print(corpus) #输出语料库 #计算语料库中\"one\"的tf值 tf=corpus.tf('one',corpus) # 1/12 print(tf) #计算语料库中\"one\"的idf值 idf=corpus.idf('one') #log(3/1) print(idf) #计算语料库中\"one\"的tf-idf值 tf_idf=corpus.tf_idf('one',corpus) print(tf_idf) TextRank算法在新冠相关文献文本分析中的应用主要体现在以下几个方面： 关键词提取 ：TextRank算法可以用于从大量的新冠相关文献中提取关键词。这些关键词可以帮助研究者快速理解文本的主题，从而更有效地浏览和理解大量的文献。 文本摘要 ：TextRank算法也可以用于生成文本摘要。在处理新冠相关文献时，TextRank可以帮助我们快速识别出文本的主题，从而更有效地浏览和理解大量的文献。 信息检索 ：在信息检索中，TextRank算法可以用于评估文档的重要性，从而提高搜索引擎的效率。 知识图谱构建 ：在知识图谱构建中，TextRank算法可以用于从文本中提取实体和关系，从而构建知识图谱。 ","date":"2023-10-18","objectID":"/tf-idf/:3:0","tags":[],"title":"TF-IDF","uri":"/tf-idf/"},{"categories":["生物文本挖掘"],"content":"参考 Lexicon Computing 基本词汇计算 (wordpress.com) 盘点 KeyBert、TextRank 等九种主流关键词提取算法原理及 Python 代码实现 - 知乎 (zhihu.com) ","date":"2023-10-18","objectID":"/tf-idf/:4:0","tags":[],"title":"TF-IDF","uri":"/tf-idf/"},{"categories":["生物文本挖掘"],"content":"API调用 #! /bin/bash id_list='/home/yh/dzx/work/BioNLP/EntityAnnotation/pmid.txt' #读取id时跳过pmid.txt第一行列名 while read line do if [ $line != 'pmid' ] then curl https://www.ncbi.nlm.nih.gov/research/pubtator-api/publications/export/pubtator?pmids=$line \u003e\u003e /home/yh/dzx/work/BioNLP/EntityAnnotation/abstract_pubtator.txt echo \u003e\u003e /home/yh/dzx/work/BioNLP/EntityAnnotation/abstract_pubtator.txt fi sleep 2 done \u003c $id_list cat abstract_pubtator.txt|grep -v '|t|' |grep -v '|a|'|awk -F\"[[:space:]]+\" '{print $5}'|head ","date":"2023-10-17","objectID":"/pubtator/:1:0","tags":[],"title":"PubTator","uri":"/pubtator/"},{"categories":[],"content":" ifelse(test, yes, no) all \u003c- inter_data %\u003e% filter(gene1 %in% tf_data | gene2 %in% tf_data) %\u003e% distinct() all$param_1 \u003c- ifelse(all$gene1 %in% tf_data, 1, 0) all$param_2 \u003c- ifelse(all$gene2 %in% tf_data, 2, 0) all$sum \u003c- all$param_1 + all$param_2 inter_data \u003c- all %\u003e% filter(sum != 0) write.csv(all, \"e:/1/TF_inter.csv\", row.names = FALSE) write.csv(inter_data, \"e:/1/TF_inter.1.0.csv\", row.names = FALSE) library(dplyr) inter_data \u003c- read.csv(\"E:/1/ear_1.csv\", header = FALSE, sep = \",\") %\u003e% select(1,5) %\u003e% mutate(param_1 = 0, param_2 = 0, sum = 0) %\u003e% rename(gene1 = V1, gene2 = V5) TF \u003c- read.csv(\"e:/1/TF_summary.csv\", header = TRUE, sep = \",\") tf_data \u003c- TF$TF_zong all_1 \u003c- inter_data %\u003e% filter(inter_data$gene1 %in% tf_data) all_2 \u003c- inter_data %\u003e% filter(inter_data$gene2 %in% tf_data) all \u003c- rbind(all_1, all_2) %\u003e% distinct() write.csv(all, \"e:/1/TF_inter.csv\", row.names = FALSE) for(i in 1:nrow(inter_data)){ if(inter_data$gene1[i] %in% tf_data){ inter_data$param_1[i] \u003c- 1 } if(inter_data$gene2[i] %in% tf_data){ inter_data$param_2[i] \u003c- 2 } inter_data$sum[i] \u003c- inter_data$param_1[i] + inter_data$param_2[i] } inter_data \u003c- inter_data %\u003e% filter(inter_data$sum != 0) write.csv(inter_data, \"e:/1/TF_inter.1.0.csv\", row.names = FALSE) #两列同时存在的 same \u003c- inter_data %\u003e% filter(inter_data$gene1 %in% tf_data \u0026 inter_data$gene2 %in% tf_data) write.csv(same, \"e:/1/TF_same.csv\", row.names = FALSE) ","date":"2023-10-09","objectID":"/r%E8%AF%AD%E8%A8%80%E7%AC%94%E8%AE%B02/:0:0","tags":[],"title":"R语言笔记2","uri":"/r%E8%AF%AD%E8%A8%80%E7%AC%94%E8%AE%B02/"},{"categories":["处理和分析高通量测序数据"],"content":"利用ChIPseeker R包对peak进行注释 经过前期的处理拿到了BED文件，利用这些文件和ChIPSeeker可以进一步对peak注释、可视化。 ","date":"2023-10-08","objectID":"/r%E5%8C%85peak%E6%B3%A8%E9%87%8A/:0:0","tags":["peak注释"],"title":"R包peak注释","uri":"/r%E5%8C%85peak%E6%B3%A8%E9%87%8A/"},{"categories":["处理和分析高通量测序数据"],"content":"指定Bioregion结合图谱可视化 网上大部分教程都是限定一个固定的窗口(比如最常用到的TSS启动子区域)，将所有的peak全部align(标准化对齐？)，可视化其结合谱图。而我想要的效果是 将**整个基因(从TSS上游限定部分至TTS下游限定部分)**作为一个窗口 类似效果如下图左侧的 original regions scaled to the same length deeptools示例 经过一系列bing搜索找到了这个问题的解决顺寻： could the \"plotAvgProf\" can get the region from TSS to TTS ? · Issue #87 · YuLab-SMU/ChIPseeker · GitHu Adding function of plotting bioregion by binning by MingLi-929 · Pull Request #156 · YuLab-SMU/ChIPseeker (github.com) Adding function of plotting bioregion by binning #156 在这个界面中，作者借鉴deeptools中computeMatrix的分bin方法归一化不同BioRegion的长度，加入了一系列函数实现上述设想目的。 但是实践后发现在最新的包里面似乎没有了这些函数，最后在bioconductor中找到一些详细的示例说明，发现函数名称功能重整。 ChIPseeker: an R package for ChIP peak Annotation, Comparison and Visualization (bioconductor.org) plotPeakProf2示例 plotPeakProf2，可以直接输入*summits.bed文件名（路径），通过指定 type = \"body\"将txdb文件中每一条序列的整个特定BioRegion作为一个窗口。 ","date":"2023-10-08","objectID":"/r%E5%8C%85peak%E6%B3%A8%E9%87%8A/:1:0","tags":["peak注释"],"title":"R包peak注释","uri":"/r%E5%8C%85peak%E6%B3%A8%E9%87%8A/"},{"categories":["处理和分析高通量测序数据"],"content":"实践流程 \u0026 代码 导入相关的包 library(ChIPseeker) #install.packages(\"RMariaDB\") library(RMariaDB) library(GenomicFeatures) library(ggimage) 获取背景注释信息 GenomicFeatures包中有函数用来制作TxDb对象： makeTxDbFromUCSC： 通过UCSC在线制作TxDb makeTxDbFromBiomart: 通过ensembl在线制作TxDb makeTxDbFromGRanges：通过GRanges对象制作TxDb makeTxDbFromGFF：通过解析GFF文件制作TxDb 通过ucsc或者ensembl数据库ftp协议下载gff文件，如 ftp://ftp.ebi.ac.uk/pub/databases/pombase/pombe/Chromosome_Dumps/gff3/schiz maize_TxDb \u003c- makeTxDbFromGFF(\"E:/seq_project/work_data/Zma_B73_V4.gff3\") 整段peak注释画图代码 bed_data_path \u003c- \"E:/seq_project/work_data/summits_bed\" orgs \u003c- c(\"ear_1\", \"ear_2\", \"shoot_1\", \"shoot_2\", \"tassel\") plot_path \u003c- \"E:/seq_project/R包peak注释/plot\" for (org in orgs){ bed_files \u003c- list.files(paste(bed_data_path, org, sep = \"/\"), pattern = \"\\\\.bed$\", full.names = TRUE) bed_names \u003c- gsub(\"_summits.*\", \"\", basename(bed_files)) names(bed_files) \u003c- bed_names bed_files \u003c- as.list(bed_files) #依次读取bed文件 for (bed_file in bed_files){ peak \u003c- readPeakFile(bed_file) peakAnno \u003c- annotatePeak(peak, tssRegion=c(-2000, 2000), TxDb=maize_TxDb) pdf(file = file.path(plot_path,\"pie\", org, paste(basename(bed_file), \"_pie\", \".pdf\", sep = \"\"))) plotAnnoPie(peakAnno) dev.off() pdf(file = file.path(plot_path,\"pie\", org, paste(basename(bed_file), \"_upset\", \".pdf\", sep = \"\"))) p \u003c- upsetplot(peakAnno, vennpie=TRUE) print(p) dev.off() } pdf(file = file.path(plot_path,\"PeakProf\", paste0(org, \"genebody_PeakProf\", \".pdf\"))) p_1 \u003c- plotPeakProf2(bed_files, upstream = 1000, downstream = 1000, conf = 0.95, by = \"gene\", type = \"body\", nbin = 800, TxDb = maize_TxDb, facet = \"row\") print(p_1) dev.off() } ","date":"2023-10-08","objectID":"/r%E5%8C%85peak%E6%B3%A8%E9%87%8A/:2:0","tags":["peak注释"],"title":"R包peak注释","uri":"/r%E5%8C%85peak%E6%B3%A8%E9%87%8A/"},{"categories":["处理和分析高通量测序数据"],"content":"其他常规可视化 CS6: ChIP数据可视化 (guangchuangyu.github.io) ","date":"2023-10-08","objectID":"/r%E5%8C%85peak%E6%B3%A8%E9%87%8A/:3:0","tags":["peak注释"],"title":"R包peak注释","uri":"/r%E5%8C%85peak%E6%B3%A8%E9%87%8A/"},{"categories":["处理和分析高通量测序数据"],"content":"参考 CS6: ChIP数据可视化 (guangchuangyu.github.io) CS4：关于ChIPseq注释的几个问题 (qq.com) ChIPseeker: an R package for ChIP peak Annotation, Comparison and Visualization (bioconductor.org) ","date":"2023-10-08","objectID":"/r%E5%8C%85peak%E6%B3%A8%E9%87%8A/:4:0","tags":["peak注释"],"title":"R包peak注释","uri":"/r%E5%8C%85peak%E6%B3%A8%E9%87%8A/"},{"categories":["处理和分析高通量测序数据"],"content":"ATAC-seq数据peak calling ","date":"2023-10-07","objectID":"/atac-seq/:1:0","tags":["ATAC-Seq"],"title":"ATAC-Seq数据处理","uri":"/atac-seq/"},{"categories":["处理和分析高通量测序数据"],"content":"fastq数据trim_galore软件质控 对双端测序的左右端结果文件进行处理 $ pwd /home/yuanhx/dzx/ATAC_seq/clean #shell脚本 bin_trim_galore=\"trim_galore\" ls ../raw/*gz | while read -r fq1 \u0026\u0026 read -r fq2; do $bin_trim_galore -q 10 --phred33 --length 35 -e 0.1 --stringency 4 --paired -o ./ $fq1 $fq2 done ","date":"2023-10-07","objectID":"/atac-seq/:1:1","tags":["ATAC-Seq"],"title":"ATAC-Seq数据处理","uri":"/atac-seq/"},{"categories":["处理和分析高通量测序数据"],"content":"bowtie2比对 用bowtie2进行比对和统计比对率,需要提前下载参考基因组然后使用命令构建索引，或者直接就下载索引文件： 这里使用下载好的参考基因组构建索引： $ pwd /home/ljx/yuanh/work_data/230926_Wheat_Ref_genome/index bowtie2-build --threads 25 ../Wheat_Ref_genome.fasta ./Wheat 双端测序数据的比对： cd /home/yuanhx/dzx/ATAC_seq/align bin_bowtie2='/home/ljx/yuanh/bin/bowtie2' bin_samtools='/home/ljx/yuanh/bin/samtools' index=\"/home/ljx/yuanh/work_data/230926_Wheat_Ref_genome/index/Wheat\" ls ../clean/*gz |while read -r fq1 \u0026\u0026 read -r fq2; do sample=$(basename $fq1 | cut -d '_' -f1) $bin_bowtie2 -p 10 -X 1000 -x $index -1 $fq1 -2 $fq2 |$bin_samtools sort -O bam -@ 20 -o -\u003e${sample}.bam done #slurm提交脚本 #!/bin/bash #SBATCH -J dzx #SBATCH -p GPU-3090-1 #SBATCH -N 1 #SBATCH -o /home/yuanhx/dzx/ATAC_seq/align/out.txt #SBATCH -e /home/yuanhx/dzx/ATAC_seq/align/err.txt # 记录开始时间 start_time=$(date +\"%Y-%m-%d %H:%M:%S\") echo \"Job started at $start_time\" # 运行任务 bash run.sh # 记录结束时间 end_time=$(date +\"%Y-%m-%d %H:%M:%S\") echo \"Job finished at $end_time\" # 计算运行时间 start_seconds=$(date -d \"$start_time\" +%s) end_seconds=$(date -d \"$end_time\" +%s) runtime=$((end_seconds - start_seconds)) echo \"Job took $runtime seconds to complete\" 对bam文件过滤 mkdir /home/yuanhx/dzx/ATAC_seq/mark_duplicate; cd $_ bin_picard='/home/ljx/yuanh/bin/picard' bin_samtools='/home/ljx/yuanh/bin/samtools' #去除PCR重复 ls ../clean/*gz |while read -r fq1 \u0026\u0026 read -r fq2; do sample=$(basename $fq1 | cut -d '_' -f1) java -jar /home/ljx/yuanh/software/picard.jar MarkDuplicates -I ../align/${sample}.bam \\ -O ${sample}.rmdup.bam -M ${sample}.rmdup.metric --REMOVE_DUPLICATES true #去除低质量reads(-q 30)以及未必对到同一条染色体(-f 2)的数据 $samtools view -h -f 2 -q 30 ${sample}.rmdup.bam | grep -v chrM | $samtools sort -O bam -@ 20 -o - \u003e${sample}.last.bam bedtools bamtobed -i ${sample}.last.bam \u003e${sample}.last.bed done ","date":"2023-10-07","objectID":"/atac-seq/:1:2","tags":["ATAC-Seq"],"title":"ATAC-Seq数据处理","uri":"/atac-seq/"},{"categories":["处理和分析高通量测序数据"],"content":"MACS2进行call peak cd /home/yuanhx/dzx/ATAC_seq/mark_duplicate ls *.bed | while read id; do macs2 callpeak -t $id -g 14300719022 --nomodel --shift -100 --extsize 200 -n ${id%%.*} --outdir ../peaks done 后续脚本整合 sbatch --dependency=afterok:21520 run.slurm run.slurm: #!/bin/bash #SBATCH -J dzx #SBATCH -p GPU-3090-1 #SBATCH -N 1 #SBATCH -o /home/yuanhx/dzx/ATAC_seq/out.txt #SBATCH -e /home/yuanhx/dzx/ATAC_seq/err.txt #SBATCH --mail-type=END #SBATCH --mail-user=2719323380@qq.com bash run.sh #run.sh mkdir /home/yuanhx/dzx/ATAC_seq/mark_duplicate; cd $_ picard='/home/ljx/yuanh/bin/picard' samtools='/home/ljx/yuanh/bin/samtools' #去除PCR重复 $picard MarkDuplicates -I ../align/${sample}.bam \\ -O ${sample}.rmdup.bam -M ${sample}.rmdup.metric --REMOVE_DUPLICATES true #去除低质量reads(-q 30)以及未必对到同一条染色体(-f 2)的数据 $samtools view -h -f 2 -q 30 ${sample}.rmdup.bam | grep -v chrM | $samtools sort -O bam -@ 20 -o - \u003e${sample}.last.bam bedtools bamtobed -i ${sample}.last.bam \u003e${sample}.last.bed cd /home/yuanhx/dzx/ATAC_seq/mark_duplicate ls *.bed | while read id; do macs2 callpeak -t $id -g 14300719022 --nomodel --shift -100 --extsize 200 -n ${id%%.*} --outdir ../peaks done ","date":"2023-10-07","objectID":"/atac-seq/:2:0","tags":["ATAC-Seq"],"title":"ATAC-Seq数据处理","uri":"/atac-seq/"},{"categories":["Perl"],"content":"运用实例 =pod 下列是一条蛋白质序列，请统计该序列长度、丙氨酸（A）的个数及所占的比例； MNAPERQPQPDGGDAPGHEPGGSPQDELDFSILFDYEYLNPNEEEPNAHKVASPPSGPAYPDDVLDYGLKPYSPLASLSGEPPGRFGEPDRVGPQKFLSAAKPAGASGLSPRIEITPSHELIQAVGPLRMRDAGLLVEQPPLAGVAASPRFTLPVPGFEGYREPLCLSPASSGSSASFISDTFSPYTSPCVSPNNGGPDDLCPQFQNIPAHYSPRTSPIMSPRTSLAEDSCLGRHSPVPRPASRSSSPGAKRRHSCAEALVALPPGASPQRSRSPSPQPSSHVAPQDHGSPAGYPPVAGSAVIMDALNSLATDSPCGIPPKMWKTSP =cut $protein_sequence = \"MNAPERQPQPDGGDAPGHEPGGSPQDELDFSILFDYEYLNPNEEEPNAHKVASPPSGPAYPDDVLDYGLKPYSPLASLSGEPPGRFGEPDRVGPQKFLSAAKPAGASGLSPRIEITPSHELIQAVGPLRMRDAGLLVEQPPLAGVAASPRFTLPVPGFEGYREPLCLSPASSGSSASFISDTFSPYTSPCVSPNNGGPDDLCPQFQNIPAHYSPRTSPIMSPRTSLAEDSCLGRHSPVPRPASRSSSPGAKRRHSCAEALVALPPGASPQRSRSPSPQPSSHVAPQDHGSPAGYPPVAGSAVIMDALNSLATDSPCGIPPKMWKTSP\"; $len = length($protein_sequence); $A_count = $protein_sequence =~ s/A/A/g; $A_per = ($A_count/$len)*100; print \"length: $len\\n\"; print \"the count of A: $A_count\\n\"; print \"the percentage of A: $A_per%\\n\"; ","date":"2023-09-19","objectID":"/perl_%E6%AD%A3%E5%88%99/:1:0","tags":["正则表达式","Perl"],"title":"perl中正则表达式","uri":"/perl_%E6%AD%A3%E5%88%99/"},{"categories":["Perl"],"content":"参考 Perl 正则表达式 | 菜鸟教程 (runoob.com) perl 统计字符串中特定字符出现的次数_ok_我的心的博客-CSDN博客 ","date":"2023-09-19","objectID":"/perl_%E6%AD%A3%E5%88%99/:2:0","tags":["正则表达式","Perl"],"title":"perl中正则表达式","uri":"/perl_%E6%AD%A3%E5%88%99/"},{"categories":["处理和分析高通量测序数据"],"content":"文件格式 BED (Browser Extensible Data),一种灵活的储存数据的格式，主要用来 储存基因组特征 （genomic features） 或注释信息(*.summits.bed) 。 BED格式可用于UCSC的Genome Browser可视化工具中 挖掘生物数据信息时，我们会将进行序列比对（未知的序列与已知的reference对比，从而找到未知序列中隐藏的信息），常见的序列比对的文件输出格式为sam和bam Sequence Alignment Mapping (SAM) 格式包括两部分：1. 注释信息（header section）2. 比对结果（alignment section） Binary Alignment/Map (BAM)是SAM格式的二进制压缩格式，这两种格式是序列比对时软件常用的数据格式 sam/bam格式文件，就是把测序reads比对到参考基因组后的文件 bam或者bed格式的文件主要是为了追踪我们的reads到底比对到了参加基因组的什么区域 ","date":"2023-09-12","objectID":"/deeptools_computematrix%E4%BD%BF%E7%94%A8%E4%BB%8B%E7%BB%8D/:1:0","tags":["deeptools","生物信息常见文件格式"],"title":"deeptools_computeMatrix使用介绍","uri":"/deeptools_computematrix%E4%BD%BF%E7%94%A8%E4%BB%8B%E7%BB%8D/"},{"categories":["处理和分析高通量测序数据"],"content":"deeptools功能 deeptools模块流程图 ","date":"2023-09-12","objectID":"/deeptools_computematrix%E4%BD%BF%E7%94%A8%E4%BB%8B%E7%BB%8D/:2:0","tags":["deeptools","生物信息常见文件格式"],"title":"deeptools_computeMatrix使用介绍","uri":"/deeptools_computematrix%E4%BD%BF%E7%94%A8%E4%BB%8B%E7%BB%8D/"},{"categories":["处理和分析高通量测序数据"],"content":"Deeptools 对 ChIP-seq 数据进行图形呈现 ","date":"2023-09-12","objectID":"/deeptools_computematrix%E4%BD%BF%E7%94%A8%E4%BB%8B%E7%BB%8D/:3:0","tags":["deeptools","生物信息常见文件格式"],"title":"deeptools_computeMatrix使用介绍","uri":"/deeptools_computematrix%E4%BD%BF%E7%94%A8%E4%BB%8B%E7%BB%8D/"},{"categories":["处理和分析高通量测序数据"],"content":"bam文件转换成bw文件格式 将bam文件转换为bigwig文件，这是一种压缩的二进制格式，可以快速加载和显示 bamCoverage -e 170 -bs 10 -b ap2_chip_rep1_2_sorted.bam -o ap2_chip_rep1_2.bw #ap2_chip_rep1_2_sorted.bam是前期比对得到的BAM文件 得到的bw文件就可以送去IGV/Jbro wse进行可视化。 这里的参数仅使用了 -e/--extendReads和 -bs/--binSize即拓展了原来的read长度，且设置分箱的大小。其他参数还有 --filterRNAstrand {forward, reverse}: 仅统计指定正链或负链 --region/-r CHR:START:END: 选取某个区域统计 --smoothLength: 通过使用分箱附近的read对分箱进行平滑化 如果为了其他结果进行比较，还需要进行标准化，deeptools提供了如下参数： --scaleFactor: 缩放系数 --normalizeUsingRPKMReads: Per Kilobase per Million mapped reads (RPKM)标准化 --normalizeTo1x: 按照1x测序深度(reads per genome coverage, RPGC)进行标准化 --ignoreForNormalization： 指定那些染色体不需要经过标准化 ","date":"2023-09-12","objectID":"/deeptools_computematrix%E4%BD%BF%E7%94%A8%E4%BB%8B%E7%BB%8D/:3:1","tags":["deeptools","生物信息常见文件格式"],"title":"deeptools_computeMatrix使用介绍","uri":"/deeptools_computematrix%E4%BD%BF%E7%94%A8%E4%BB%8B%E7%BB%8D/"},{"categories":["处理和分析高通量测序数据"],"content":"computeMatrix 计算每个基因组区域的得分，并生成一个可与 plotHeatmap 和 plotProfiles 一起使用的中间文件。 Required arguments: --regionsFileName File [File ...], -R File [File ...] File name or names, in BED or GTF format, containing the regions to plot. If multiple bed files are given, each one is considered a group that can be plotted separately. Also, adding a \"#\" symbol in the bed file causes all the regions until the previous \"#\" to be considered one group.(default: None) --scoreFileName File [File ...], -S File [File ...] bigWig file(s) containing the scores to be plotted. Multiple files should be separated by spaced. BigWig files can be obtained by using the bamCoverage or bamCompare tools. More information about the bigWig file format can be found at http://genome.ucsc.edu/goldenPath/help/bigWig.html(default: None) computeMatrix 有两种主要的使用模式/参数 computeMatrix reference-point reference-point 计算的基因组区域以某一个位置点作为相对参考点 --referencePoint {TSS,TES,center} region start (TSS) the region end(TES) the center of the region （默认为TSS） computeMatrix scale-regions scale-regions 计算的基因组区域为一段设定的区域长度（-b -a -m三个参数设置控制） #对单一样本绘图 computeMatrix scale-regions \\ -S shoot_ATAC-seq.bigwig \\ -R gene_length.bed \\ -b 1000 -a 1000 \\ -bs 50 \\ --skipZeros \\ -o matrix1_shoot_all.gz --outFileSortedRegions region1_shoot_genes.bed plotHeatmap -m matrix1_shoot_all.gz -out shoot_Heatmap.png ","date":"2023-09-12","objectID":"/deeptools_computematrix%E4%BD%BF%E7%94%A8%E4%BB%8B%E7%BB%8D/:3:2","tags":["deeptools","生物信息常见文件格式"],"title":"deeptools_computeMatrix使用介绍","uri":"/deeptools_computematrix%E4%BD%BF%E7%94%A8%E4%BB%8B%E7%BB%8D/"},{"categories":["处理和分析高通量测序数据"],"content":"参考 computeMatrix — deepTools 3.2.1 documentation (test-argparse-readoc.readthedocs.io) [生信资料 3] 生物信息学常见数据格式，汇总！ - 知乎 (zhihu.com) [软件使用05] 快速使用 Deeptools 对 ChIP-seq 数据画图！ - 知乎 (zhihu.com) ATAC-seq-TSS富集图-deeptools-学习笔记 - 知乎 (zhihu.com) ","date":"2023-09-12","objectID":"/deeptools_computematrix%E4%BD%BF%E7%94%A8%E4%BB%8B%E7%BB%8D/:4:0","tags":["deeptools","生物信息常见文件格式"],"title":"deeptools_computeMatrix使用介绍","uri":"/deeptools_computematrix%E4%BD%BF%E7%94%A8%E4%BB%8B%E7%BB%8D/"},{"categories":["GSEA"],"content":"GSEA的结果图 GSEA的结果图通常包含三个部分 ","date":"2023-09-09","objectID":"/gsea_results/:1:0","tags":["ES折线图","信噪比"],"title":"GSEA结果理解","uri":"/gsea_results/"},{"categories":["GSEA"],"content":"富集分数（Enrichment Score）的折线图 横轴代表排序后的基因，纵轴为对应的Running ES。在折线图中出现的峰值就是这个基因集的富集分数（Enrichment Score，ES）。ES是从排序后的表达基因集的第一个基因开始，如果排序表达基因集中的基因出现在功能基因数据集中则加分，反之则减分。正值说明在顶部富集，峰值左边的基因为核心基因，负值则相反。 富集分数（ES） ES计算公式 正值ES表示基因 在功能注释基因集的顶部富集，负值ES表示基因 在功能注释基因集的底部富集。 ","date":"2023-09-09","objectID":"/gsea_results/:1:1","tags":["ES折线图","信噪比"],"title":"GSEA结果理解","uri":"/gsea_results/"},{"categories":["GSEA"],"content":"基因位置图 黑线代表排序后表达数据集中的基因存处于当前分析的功能注释基因集的位置 红蓝相间的热图是表达丰度排列，红色越深的表示该位置的基因logFC越大，蓝色越深表示logFC越小。如果研究的功能注释基因集的成员显著聚集在表达数据集的顶部或底部，则说明功能基因数据集中的基因在数据集中高表达或低表达，若随机分配，则说明表达数据集与该通路无关。 ","date":"2023-09-09","objectID":"/gsea_results/:1:2","tags":["ES折线图","信噪比"],"title":"GSEA结果理解","uri":"/gsea_results/"},{"categories":["GSEA"],"content":"信噪比（Signal2Noise） 每个基因对应的信噪比以灰色面积图显示。灰色阴影的面积比，可以从整体上反映组间的Signal2Noise的大小。 在GSEA（基因集富集分析）中，信噪比（Signal-to-Noise Ratio）是一种度量方法，用于对基因进行排序。这种排序方法是根据基因在两种样品中的差异表达程度或者表型相关度进行排序 具体来说，信噪比的计算方法如下： 信噪比的计算方法 首先，对所有基因按照它们在两种样品中的差异表达程度（如logFC）或者表型相关度进行排序。 然后，对于每一个基因，计算它在样品A中的平均表达量和样品B中的平均表达量的差值。这个差值就是该基因的信噪比。 在GSEA的结果展示图中，每个基因对应的信噪比以灰色面积图显示。灰色阴影的面积比，可以从整体上反映组间的Signal2Noise的大小。 GSEA图 在上图中，我们一般关注ES值，峰出现在排序基因集的前端还是后端（ES值大于0在前端，小于0在后端）以及 Leading edge subset（即对富集贡献最大的部分，领头亚集）；在ES图中出现领头亚集的形状，表明这个功能基因集在某处理条件下具有更显著的生物学意义。 ","date":"2023-09-09","objectID":"/gsea_results/:1:3","tags":["ES折线图","信噪比"],"title":"GSEA结果理解","uri":"/gsea_results/"},{"categories":["GSEA"],"content":"GSEA计算中几个关键概念 NES ：校正后的归一化的ES值 由于不同用户输入的基因数据库文件中的基因集数目可能不同，富集评分的标准化考虑了基因集个数和大小，其绝对值大于 1为一条富集标准。 FDR q-val：是多重假设检验校正之后的 p-value 即对 NES可能存在的假阳性结果的概率估计（多重假设检验校正 ：首先对每个基因子集 计算得到的ES根据基因集的大小进行标准化得到Normalized Enrichment Score (NES)。随后针对NES计算假阳性率） LEADING EDGE： 该处有3个统计值，tags=**%表示核心基因占该基因集中基因总数的百分比；list=**%表示核心基因占所有基因的百分比；signal=**%，将前两项统计数据结合在一起计算出的富集信号强度，计算公式如下： signal计算公式 核心基因：leading edge subset 指在该基因集中，对于富集结果的贡献最大的基因。 GSEA 对显著性的定义为 p-value\u003c5%，FDR q-val\u003c25% ","date":"2023-09-09","objectID":"/gsea_results/:1:4","tags":["ES折线图","信噪比"],"title":"GSEA结果理解","uri":"/gsea_results/"},{"categories":["GSEA"],"content":"参考 GSEA第2弹！如何解读GSEA富集结果 - 知乎 (zhihu.com) 史上最全GSEA可视化教程，今天让你彻底搞懂GSEA！ - 知乎 (zhihu.com) 一文掌握GSEA，超详细教程！ - 知乎 (zhihu.com) ","date":"2023-09-09","objectID":"/gsea_results/:2:0","tags":["ES折线图","信噪比"],"title":"GSEA结果理解","uri":"/gsea_results/"},{"categories":["GSEA"],"content":"GESA富集分析可以使用 java 版本的 GSEA软件进行富集。但是这个软件有一个问题就是自带的物种数据库有限（主要是人、小鼠的 PMT 文件、且不支持 KEGG 库），如果想要分析一些其他物种，需要上传自己准备的 PMT 文件。 这时候有一个可选的方案就是用 clusterProfiler包进行 GSEA 富集分析，该软件提供了两种方式进行富集： gseGO、gseKEGG等函数分别从 OrgDb、KEGG 官网读取或者下载 PMT 基因集 GSEA函数，一个通用的 GSEA 富集框架，支持从本地读取自己已经准备好的 PMT 基因集 ","date":"2023-08-29","objectID":"/clusterprofiler_gesa/:0:0","tags":["clusterProfiler","GESA"],"title":"clusterProfiler包GSEA富集","uri":"/clusterprofiler_gesa/"},{"categories":["GSEA"],"content":"gseGO gseGO( geneList, ont = \"BP\", OrgDb, keyType = \"ENTREZID\", exponent = 1, minGSSize = 10, maxGSSize = 500, eps = 1e-10, pvalueCutoff = 0.05, pAdjustMethod = \"BH\", verbose = TRUE, seed = FALSE, by = \"fgsea\", ... ) geneList order ranked geneList 根据 logFC(log2folderchange)列进行 降序排列（上调基因在顶部，下调在底部），制作 gene_list集(logFC对应元素名为对应基因id): GSEA_input \u003c- info_merge$Log2FoldChange names(GSEA_input) = info_merge$ENTREZID geneList \u003c- sort(GSEA_input, decreasing = TRUE) gseGO:GO 本体富集，可以进行GO本体的GSEA富集 gsea_go \u003c- gseGO( gene_list, # 根据logFC排序的基因集 ont = \"BP\", # 可选\"BP\"、\"MF\"、\"CC\"三大类或\"ALL\" OrgDb = maize, #orgdb数据库 keyType = \"ENTREZID\", # 基因id类型 pvalueCutoff = 0.05, pAdjustMethod = \"BH\", # p值校正方法 ) 查看分析结果数据和对应列名 head(gsea_go,2) ID ：GO term 或 KEGG 通路 Description ：GO term 描述信息 setSize ：富集到该 term 的基因个数 enrichmentScore ：富集分数，也就是 ES NES ：标准化以后的 ES，全称 normalized enrichment score pvalue：富集的 P 值 p.adjust ：校正后的 P 值 qvalues ：FDR （false discovery rate）错误发现率 rank ：当 ES 最大时，对应基因所在排序好的基因列表中所处的位置 leading_edge：tags 表示核心基因占该通路基因集的百分比；list 表示核心基因占所有基因的百分比；signal，将前 2 项统计值结合在一起计算出的富集信号强度 core_enrichment：核心或者 leading 基因列表。 ","date":"2023-08-29","objectID":"/clusterprofiler_gesa/:1:0","tags":["clusterProfiler","GESA"],"title":"clusterProfiler包GSEA富集","uri":"/clusterprofiler_gesa/"},{"categories":["GSEA"],"content":"上、下调的 GO term 分开展示： dotplot( gsea_go, showCategory=10, split=\".sign\") + facet_grid(.~.sign) ","date":"2023-08-29","objectID":"/clusterprofiler_gesa/:1:1","tags":["clusterProfiler","GESA"],"title":"clusterProfiler包GSEA富集","uri":"/clusterprofiler_gesa/"},{"categories":["“GSEA\""],"content":"基因集富集分析 GSEA 传统KEGG（通路富集分析）和GO（功能富集）分析时，如果富集到的同一通路下，既有上调差异基因，也有下调差异基因，那么这条通路总体的表现形式究竟是怎样？是被抑制还是激活？或者更直观点说，这条通路下的基因表达水平在实验处理后是上升了呢，还是下降了呢? 传统的富集分析，针对总体的差异基因，不区分哪些差异基因是上调还是下调。 上调基因是指在实验组中相对于对照组表达量上升的基因，下调基因是指在实验组中相对于对照组表达量下降的基因。这些基因的变化可能会对生物体的生理和病理状态产生影响。 举个例子，有100个人（差异基因）去参加选秀节目，这里边有唱歌好的，有跳舞好的，有作词好的（各种背景），接着我们按照100个人的身高排序后发现，身高较低的选手大部分被分到了舞蹈组，因此我们获得这样一个结论，身高较低的选手跳舞身体协调性更好！这样，应用到我们的基因功能分析上，就像下图，假如按照差异表达倍数从正到负排序后（Gene set S），我们参与某条通路的差异基因密集排列在排序表顶端（Leading edge subset），及显著上调，因此我们认为这条通路下的基因表达水平在实验处理后是显著上调，可能被激活。 ","date":"2023-08-24","objectID":"/gesa/:0:0","tags":["定义","初体验"],"title":"GSEA简介","uri":"/gesa/"},{"categories":["“GSEA\""],"content":"参考 一文掌握GSEA，超详细教程！ - 知乎 (zhihu.com) 一分钟了解GSEA - 知乎 (zhihu.com) ","date":"2023-08-24","objectID":"/gesa/:1:0","tags":["定义","初体验"],"title":"GSEA简介","uri":"/gesa/"},{"categories":["GWAS"],"content":"GWAS的数据处理和质量控制：学习如何对基因型数据进行格式转换、质量过滤、正负链翻转、基因型填补等操作，以及如何评估数据质量和避免潜在的偏差","date":"2023-08-05","objectID":"/gwas_turtorial/","tags":["数据处理","质量控制"],"title":"Gwas_turtorial","uri":"/gwas_turtorial/"},{"categories":["GWAS"],"content":"GWAS主要步骤 选择一个感兴趣的性状或疾病，以及一个适当的样本群体，如病例和对照组，或者具有连续性状值的个体。 对样本进行全基因组分型，即测定数百万个SNP位点的基因型。 对每个SNP位点进行关联分析，即计算其与性状或疾病的相关性强度和显著性水平，通常使用回归模型或卡方检验等统计方法。 根据设定的显著性阈值，筛选出具有显著关联信号的SNP位点，并绘制曼哈顿图（manhattan plot）来展示全基因组关联结果。 对显著关联信号进行进一步的验证和解释，如进行基因型插补（genotype imputation），精细定位（fine-mapping），功能注释（functional annotation），共定位分析（colocalization analysis）等，以确定最可能的因果变异和相关基因。 ","date":"2023-08-05","objectID":"/gwas_turtorial/:1:0","tags":["数据处理","质量控制"],"title":"Gwas_turtorial","uri":"/gwas_turtorial/"},{"categories":["GWAS"],"content":"GWAS分析基本流程及分析思路 GWAS分析基本流程及分析思路 (qq.com) ","date":"2023-08-05","objectID":"/gwas_turtorial/:2:0","tags":["数据处理","质量控制"],"title":"Gwas_turtorial","uri":"/gwas_turtorial/"},{"categories":["GWAS"],"content":"GWAS的数据QC qc,(quality control)质量控制，比起表观学研究，GWAS研究很少有引起偏差的来源，一般来说，一个人的基因型终其一生几乎不会改变的，因此很少存在同时影响表型又影响基因型的变异。但即便这样，我们在做GWAS时也要去除一些可能引起偏差的因素。 这种因素主要有：群体结构、个体间存在血缘关系、技术性操作。 ","date":"2023-08-05","objectID":"/gwas_turtorial/:3:0","tags":["数据处理","质量控制"],"title":"Gwas_turtorial","uri":"/gwas_turtorial/"},{"categories":["GWAS"],"content":"怎么进行质量控制（PLINK） 质量控制包括两个方向，一个是样本的质量控制，一个是SNP的质量控制 必须先进行SNP过滤，才能进行个体过滤 ??? PLINK 对于PLINK来说，它既可以处理文本格式的文件，也可以处理二进制格式的文件。但是大文本的文件处理起来十分消耗计算资源，所以我们一般 推使用二进制格式的输入文件 。 文本格式的PLINK数据包括两份文件 .ped文件 和 .map文件 ped文件 包含个体信息（例如个体标识符ID，性别等等）以及他们的基因型信息 map文件 包含遗传标记的信息（染色体号，snp号等等） 二进制格式的PLINK数据则包括三份文件 ：.bed文件，.fam文件 和 .bim文件 bed文件 含有 每个个体的识别符（ID） 和每个个体相对应的基因型 fam文件 含有 个体信息 （例如性别之类的） bim文件 含有 遗传标记的信息 （染色体号，snp号等等） PLIINK基础使用命令 plink --bfile MY_DATA --assoc --out gwas_results ‐‐file {your_file}输入文本格式文件 ‐‐bfile {your_file} 输入二进制格式文件 –assoc 关联分析,这一步会对每个SNP和研究者感兴趣的性状进行卡方检验 –out {outfile} 输出文件 样本质量控制 样本的质量控制包括：缺失率、杂合性、基因型性别和记录的性别是否一致。 检测缺失率(个体缺失)，一般将样本缺失率大于5%的个体去除 plink --bfile file --mind 0.05 --make-bed --out file_mind 检测杂合性 plink --bfile file --het --make-bed --out file_het 阈值设置：偏差可能表明样品污染，近亲繁殖。我们建议去除偏离样本的杂合率平均值±3 SD的个体 检测性别不一致的个体 – 受试者信息填写的性别和遗传性别不一致 plink --bfile file --check-sex --make-bed --out file_checksex 将上述筛选出来的不符合的样本去除 plink --bfile file --remove removesample.txt --make-bed --out file_qcsample ","date":"2023-08-05","objectID":"/gwas_turtorial/:3:1","tags":["数据处理","质量控制"],"title":"Gwas_turtorial","uri":"/gwas_turtorial/"},{"categories":["GWAS"],"content":"处理群体分层 ","date":"2023-08-05","objectID":"/gwas_turtorial/:4:0","tags":["数据处理","质量控制"],"title":"Gwas_turtorial","uri":"/gwas_turtorial/"},{"categories":["GWAS"],"content":"参考 一篇手把手教你做GWAS的Guideline文献解读 - 知乎 (zhihu.com) 全基因组关联分析学习资料（GWAS tutorial） - 知乎 (zhihu.com) easyGWAS - Running GWAS easily over the web (mpg.de) ","date":"2023-08-05","objectID":"/gwas_turtorial/:5:0","tags":["数据处理","质量控制"],"title":"Gwas_turtorial","uri":"/gwas_turtorial/"},{"categories":["GWAS"],"content":"2023-8-3新开一坑，开始学GWAS GWAS学习可以分为以下几个板块： GWAS的基本概念和原理：了解GWAS的目的、方法、优势和局限性，以及常用的统计模型和假设检验。 GWAS的数据处理和质量控制：学习如何对基因型数据进行格式转换、质量过滤、正负链翻转、基因型填补等操作，以及如何评估数据质量和避免潜在的偏差。 GWAS的关联分析和结果解读：学习如何使用不同的软件和工具进行关联分析，如何绘制曼哈顿图、QQ图等可视化结果，以及如何根据P值、置信区间、效应大小等指标判断关联性的显著性和强度。 GWAS的后续分析和功能注释：学习如何进行条件分析、Meta分析、基因多效性分析、孟德尔随机化分析等进一步探索关联信号的方法，以及如何利用数据库和工具进行SNP功能注释、基因集富集分析、组织特异性表达分析等方法，以揭示关联信号的生物学意义。 GWAS的文献阅读和案例学习：学习如何阅读和评价GWAS相关的文献，了解不同疾病或性状的GWAS发现和进展，以及如何应用GWAS结果进行风险评估、药物发现等应用。 GWA_tutorial：这是一个GitHub项目，提供了一个在Linux下学习GWAS实操数据的教程，包括四个部分：数据质量控制、群体分层校正、关联分析和多基因风险得分分析。 Genome-wide association studies in R：这是一个R博客文章，提供了一个用R语言分析GWAS的流程，包括数据质量控制、PCA分析、曼哈顿图、QQ图和候选位点功能分析。 ","date":"2023-08-02","objectID":"/gwas/:0:0","tags":["定义","初理解"],"title":"GWAS初体验","uri":"/gwas/"},{"categories":["GWAS"],"content":"GWAS基本概念 GWAS利用全基因组范围内的分子标记，如单核苷酸多态性（SNP），来探索与复杂性状或疾病相关的遗传变异 GWAS的目的是发现与表型变异有统计学关联的基因或基因区域，从而揭示生物学机制和潜在的治疗靶点 ","date":"2023-08-02","objectID":"/gwas/:1:0","tags":["定义","初理解"],"title":"GWAS初体验","uri":"/gwas/"},{"categories":["GWAS"],"content":"SNP 单核苷酸多态性 单核苷酸多态性（SNP）是指DNA序列中单个核苷酸的变异，它是生物遗传多样性的一种重要形式。SNP可以分布在基因的编码区或非编码区，影响基因的功能和表达。SNP也可以用于研究生物的起源、进化、迁移、疾病相关基因和药物反应等方面。 ","date":"2023-08-02","objectID":"/gwas/:2:0","tags":["定义","初理解"],"title":"GWAS初体验","uri":"/gwas/"},{"categories":["GWAS"],"content":"GWAS主要步骤 选择一个感兴趣的性状或疾病，以及一个适当的样本群体，如病例和对照组，或者具有连续性状值的个体。 对样本进行全基因组分型，即测定数百万个SNP位点的基因型。 对每个SNP位点进行关联分析，即计算其与性状或疾病的相关性强度和显著性水平，通常使用回归模型或卡方检验等统计方法。 根据设定的显著性阈值，筛选出具有显著关联信号的SNP位点，并绘制曼哈顿图（manhattan plot）来展示全基因组关联结果。 对显著关联信号进行进一步的验证和解释，如进行基因型插补（genotype imputation），精细定位（fine-mapping），功能注释（functional annotation），共定位分析（colocalization analysis）等，以确定最可能的因果变异和相关基因。 ","date":"2023-08-02","objectID":"/gwas/:3:0","tags":["定义","初理解"],"title":"GWAS初体验","uri":"/gwas/"},{"categories":["GWAS"],"content":"GWAS优势 可以在不依赖先验知识的情况下，全面地探索遗传变异与表型之间的关系，发现一些意想不到的新发现。此外，GWAS可以利用大规模的样本数据和高密度的分子标记，提高统计学效力和解析力 ","date":"2023-08-02","objectID":"/gwas/:4:0","tags":["定义","初理解"],"title":"GWAS初体验","uri":"/gwas/"},{"categories":["GWAS"],"content":"GWAS的局限性 GWAS通常只能解释表型变异中很小一部分的遗传力（heritability），这被称为“丢失的遗传力”（missing heritability）问题。这可能是由于一些罕见变异、结构变异、基因-基因相互作用、基因-环境相互作用等未被GWAS检测到的遗传因素所造成的。 GWAS通常只能发现与表型有关联而非因果关系的变异，这需要通过实验验证或其他方法来进一步证实。此外，GWAS也不能直接提供变异对表型影响的机制和途径，这需要结合其他功能基因组学数据和方法来进行解析。 ","date":"2023-08-02","objectID":"/gwas/:5:0","tags":["定义","初理解"],"title":"GWAS初体验","uri":"/gwas/"},{"categories":["GWAS"],"content":"参考 GWAS研究基本概念1 - 知乎 (zhihu.com) ","date":"2023-08-02","objectID":"/gwas/:6:0","tags":["定义","初理解"],"title":"GWAS初体验","uri":"/gwas/"},{"categories":["R"],"content":"运用代码 keywords \u003c- c(\"calcium\", \"calmodulin\") matched_indices \u003c- sapply(keywords, function(keyword){ str_detect(GO@result$Description, fixed(keyword, ignore_case = T)) }) matched_indices \u003c- apply(matched_indices, 1, any) matched_terms \u003c- GO@result[matched_indices,] ","date":"2023-07-30","objectID":"/23.7.30_r/:1:0","tags":["apply","“str_detect\""],"title":"23.7.30_R","uri":"/23.7.30_r/"},{"categories":["hugo_blog"],"content":"搭建博客记录 ","date":"2023-07-28","objectID":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/:0:0","tags":["hugo","github pages"],"title":"搭建博客","uri":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/"},{"categories":["hugo_blog"],"content":"选择Hugo\u0026Githubpages的原因 Hugo是一个用Go语言编写的静态网站生成器，它可以快速地创建和发布博客文章。基础运用可以简单，只需要安装Hugo，选择一个主题，编写Markdown格式的文章，然后使用Hugo命令生成静态网站文件，不需要担心数据库、服务器等问题 GitHub Pages是一个静态站点托管服务，直接将个人、组织或项目的页面托管于GitHub库或仓库中。使用GitHub可以创建一个 \u003cusername\u003e.github.io的网站，不需要第一时间考虑域名以及备案等问题，后续有时间可以折腾–更改至自己的域名 GitHub workflow 可以自动更新Hugo 博客，这是一个很方便的功能。只需要将 Hugo 源码 push 到 GitHub 上，就可以触发 GitHub Actions 来生成和部署您的静态网站文件。您不需要在本地运行 Hugo 命令，也不需要手动上传文件到服务器 LoveIt主题个人比较喜欢，相对wordpress上大部分跟简洁，想要花哨也可以自定义魔改主题👴 ","date":"2023-07-28","objectID":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/:1:0","tags":["hugo","github pages"],"title":"搭建博客","uri":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/"},{"categories":["hugo_blog"],"content":"基于Hugo\u0026Githubpages的博客搭建流程 ","date":"2023-07-28","objectID":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/:2:0","tags":["hugo","github pages"],"title":"搭建博客","uri":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/"},{"categories":["hugo_blog"],"content":"基本流程 安装 Hugo。可以从[Hugo官网]下载适合您的操作系统的版本，建议下载entende版本（由于很多主题的一些特性需要将 SCSS 转换为 CSS, 推荐使用 Hugo extended版本来获得更好的使用体验 ） 可以使用 hugo version or hugo -h来检验是否安装成功 创建一个新的 Hugo 站点。可以使用 hugo new site path/to/site命令在指定的路径下创建一个空的站点框架 下载主题模板，我使用的是Git 模块方式添加主题到指定文件夹下 git submodule add https://github.com/griedzx/LoveIt.git themes/LoveIt 我将LoveIt模板文件fork到自己的仓库，并使用 git submodule（日后自己个性化模板，可以一键同步更新） 相应设置 config.toml，指定主题、网址，可以参考对应主题中的toml文件 hugo new posts/\u003cxxx\u003e.md创建markdown文件作文博文 hugo serve -D 启动 Hugo server 并使用 drafts 模式，在本地运行一个 web 服务器来预览网站效果，并且可以看到草稿文件的预览 使用GitHub可以创建一个 \u003cusername\u003e.github.io的仓库，将 hugo后产生的 ./public（里面存放的是可部署的静态网站文件）push至对应repo 7.1 GitHub workflow 可以自动更新您的 Hugo 博客，这是一个很方便的功能。只需要将您Hugo 源码 push 到 GitHub 上（可以是另一个repo，也可以是上述repo另一个分支），就可以触发 GitHub Actions 来自动生成和部署的静态网站文件 如果想了解更多关于 GitHub workflow 的信息，您可以参考Host on Github Pages | Hugo ","date":"2023-07-28","objectID":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/:2:1","tags":["hugo","github pages"],"title":"搭建博客","uri":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/"},{"categories":["hugo_blog"],"content":"设置的tips 文件头扉页 front matter title: \"搭建博客\" date: 2023-07-28T21:57:35+08:00 draft: false hugo一个新md文件一般只会出现前三行设置参数，但是Hugo 将内容分成草稿 Draft，将来发布 Future 和过期 Expired 等类型，可以在文件头扉页 front matter 中设置相应状态。 future 设置 publishdate 值 draft 设置 true 或者 false past 设置 expirydate 值 如 demo.md 文件头扉页 front matter 中设置： --- title: Base Templates and Blocks linktitle: description: The base and block constructs ... godocref: https://golang.org/pkg/text/template/#example_Template_block date: 2017-02-01 publishdate: 2017-02-01 lastmod: 2017-02-01 categories: [templates,fundamentals] keywords: [blocks,base] menu: docs: parent: \"templates\" weight: 20 weight: 20 sections_weight: 20 draft: false aliases: [/templates/blocks/,/templates/base-templates-and-blocks/] toc: true --- 多语言模式 [language]下设置多种参数，具体见多语言模式 |雨 果 (gohugo.io) 对于每个新页面, 将语言代码附加到文件名中. 单个文件 my-page.md 需要分为三个文件: 英语: my-page.en.md 中文: my-page.zh-cn.md 法语: my-page.fr.md emoji展示 win10输入法里面 徽标 + 句号（.）可以使用自带的表情符号，可以个性化设置 🐱‍🏍 好玩 以上完成初步hugo网站的搭建，还有很多设置可以学习。hugo官方的汉化版使用文档很简略，大部分网上找到的翻译文档大多直译看完后还是摸不着头脑，在简书上发现Hugo 不完美教程 这一系列教程，使用文档和作者实战经验相结合，对我有很大帮助，我将借助此继续完善我的网站 参考 Hugo 不完美教程 - I: Hugo Web Framework - 简书 (jianshu.com) Hugo框架中文文档 标签分类 - Andbible ","date":"2023-07-28","objectID":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/:2:2","tags":["hugo","github pages"],"title":"搭建博客","uri":"/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/"},{"categories":["GO\u0026KEGG富集分析"],"content":"问题描述 做GO富集分析时，师姐给的数据是Genome assembly B73 RefGen_v4版本的数据 对应基因id没有需要使用的symbol或者entrez_id形式 并且大多数在线GO分析网站和id转换网站不支持v4版本基因id与symbol或者entrez_id相互转换 Genome assembly B73 RefGen_v4 Genome assembly B73 RefGen_v4是玉米的第四版参考基因组序列，它是由美国农业部农业研究局（USDA-ARS）和美国能源部联合基因组研究所（DOE-JGI）的科学家合作完成的。它是目前最完整、最准确的玉米基因组序列，它包含了21条染色体的端粒到端粒的连续序列，共有2.06亿个碱基对，覆盖了99.8%的可编码区域，注释了39,656个基因。 ","date":"2023-07-18","objectID":"/maize_gene_id%E8%BD%AC%E6%8D%A2/:1:0","tags":["maize_gene_id"],"title":"maize_gene_id转换","uri":"/maize_gene_id%E8%BD%AC%E6%8D%A2/"},{"categories":["GO\u0026KEGG富集分析"],"content":"解决方法 ","date":"2023-07-18","objectID":"/maize_gene_id%E8%BD%AC%E6%8D%A2/:2:0","tags":["maize_gene_id"],"title":"maize_gene_id转换","uri":"/maize_gene_id%E8%BD%AC%E6%8D%A2/"},{"categories":["GO\u0026KEGG富集分析"],"content":"网页在线转换 MaizeGDB gene Search Page MaizeGDB数据库有一个Translate Gene Model IDs工具，可以识别各种类型的玉米的gene_id，并转换为比较常用的几种id(如) ","date":"2023-07-18","objectID":"/maize_gene_id%E8%BD%AC%E6%8D%A2/:2:1","tags":["maize_gene_id"],"title":"maize_gene_id转换","uri":"/maize_gene_id%E8%BD%AC%E6%8D%A2/"},{"categories":["GO\u0026KEGG富集分析"],"content":"爬虫技术解决 R语言爬取NCBI大豆基因Locus tag数据 - 简书 (jianshu.com) 生信笔记01：Locus tag转换为Entrez Gene ID - 简书 (jianshu.com) 通过 ","date":"2023-07-18","objectID":"/maize_gene_id%E8%BD%AC%E6%8D%A2/:2:2","tags":["maize_gene_id"],"title":"maize_gene_id转换","uri":"/maize_gene_id%E8%BD%AC%E6%8D%A2/"},{"categories":["GO\u0026KEGG富集分析"],"content":"AnnotationHub构建OrgDb 要进行GO或者KEGG富集分析，就需要知道每个基因对应什么样的GO/KEGG分类，OrgDb就是存储不同数据库基因ID之间对应关系，以及基因与GO等注释的对应关系的 R 软件包 如果自己研究的物种不在 http://bioconductor.org/packages/release/BiocViews.html#___OrgDb 之列，很大可能就需要自己构建OrgDb，然后用clusterProfiler分析 ","date":"2023-07-17","objectID":"/annotationhub%E6%9E%84%E5%BB%BAorgdb/:0:0","tags":["AnnotationHub","OrgDb"],"title":"Annotationhub构建orgdb","uri":"/annotationhub%E6%9E%84%E5%BB%BAorgdb/"},{"categories":["GO\u0026KEGG富集分析"],"content":"利用AnnotationHub得到org.db 其中一种情况是在（AnnotationHub）中存在对应的注释包 require(AnnotationHub) hub \u003c- AnnotationHub()#下载失败多试几次 query(hub,\"zea mays\") AnnotationHub with 8 records # snapshotDate(): 2023-04-24 # $dataprovider: NCBI,DBCLS, ftp://ftp.ncbi.nlm.nih.gov/gene/DATA/, WikiPathways # $species: Zea mays, Zea mays_var._japonica # $rdataclass: SQLiteFile, OrgDb, Tibble # additional mcols(): taxonomyid, genome, description, coordinate_1_based, maintainer, rdatadateadded, preparerclass, tags, # rdatapath, sourceurl, sourcetype # retrieve records with, e.g., 'object[[\"AH91642\"]]' title AH91642 | MeSHDb for Zea mays (Corn, v001) AH91817 | wikipathways_Zea_mays_metabolites.rda AH97909 | MeSHDb for Zea mays (Corn, v002) AH100374 | MeSHDb for Zea mays (Corn, v003) AH107139 | MeSHDb for Zea mays (Corn, v004) AH111528 | MeSHDb for Zea mays (Corn, v005) AH111691 | org.Zea_mays.eg.sqlite AH111692 | org.Zea_mays_var._japonica.eg.sqlite 阅读命令输出信息，可以看到 数据库来源不同，选择需要的（org）以及确定物种（zea_mays） retrieve records with, e.g., 'object[[\"AH111691\"]]' 检索下载db用指定格式 ","date":"2023-07-17","objectID":"/annotationhub%E6%9E%84%E5%BB%BAorgdb/:1:0","tags":["AnnotationHub","OrgDb"],"title":"Annotationhub构建orgdb","uri":"/annotationhub%E6%9E%84%E5%BB%BAorgdb/"},{"categories":["GO\u0026KEGG富集分析"],"content":"GO_KEGG富集分析 ","date":"2023-07-16","objectID":"/go_kegg%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/:0:0","tags":null,"title":"Go_kegg富集分析","uri":"/go_kegg%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/"},{"categories":["GO\u0026KEGG富集分析"],"content":"富集分析 富集分析（ Enrichment Analysis），是一种识别基因集合与已知生物过程、细胞组分和通路之间关联的统计方法。这些工具通过使用数据库中的注释信息来找到对应的基因集合。 ","date":"2023-07-16","objectID":"/go_kegg%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/:1:0","tags":null,"title":"Go_kegg富集分析","uri":"/go_kegg%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/"},{"categories":["GO\u0026KEGG富集分析"],"content":"富集分析的效果、目的 把差异基因或者物质根据其功能进行归类，使具有相似功能的基因或者物质就被放在一起 实现功能和表型相关联 解读一组基因背后所代表的生物学知识，揭示其在细胞内或细胞外扮演了什么样的角色。 ","date":"2023-07-16","objectID":"/go_kegg%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/:1:1","tags":null,"title":"Go_kegg富集分析","uri":"/go_kegg%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/"},{"categories":["GO\u0026KEGG富集分析"],"content":"富集分析的原理 富集分析通常是分析一组基因在某个功能节点上是否相比于随机水平过于出现(over-presentation) ","date":"2023-07-16","objectID":"/go_kegg%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/:1:2","tags":null,"title":"Go_kegg富集分析","uri":"/go_kegg%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/"},{"categories":["GO\u0026KEGG富集分析"],"content":"常用方法 目前最常用的方法是基于GO和KEGG的富集分析。 首先通过多种方法得到大量的感兴趣的基因，例如差异表达基因集、共表达基因模块、蛋白质复合物基因簇等，然后寻找这些感兴趣基因集显著富集的GO节点或者KEGG通路，这有助于进一步深入细致的实验研究。 依据富集分析过程中基因选择、注释数据库的不同，常用的富集分析可以分为以下四种类型：GO term功能富集、KEGG pathway通路富集、MSigDB基因集富集和单基因富集等等 ","date":"2023-07-16","objectID":"/go_kegg%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/:1:3","tags":null,"title":"Go_kegg富集分析","uri":"/go_kegg%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/"},{"categories":["GO\u0026KEGG富集分析"],"content":"GO \u0026 KEGG是什么 对于每个基因而言，其基本的功能基于他们的蛋白结构域以及研究的文献已经可以大致的知道一个基因具有什么样子的功能了。GO和KEGG就是基于不同的分类思想而储存的基因相关功能的数据库。 ","date":"2023-07-16","objectID":"/go_kegg%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/:2:0","tags":null,"title":"Go_kegg富集分析","uri":"/go_kegg%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/"},{"categories":["GO\u0026KEGG富集分析"],"content":"GO数据库 全称是Gene Ontology(基因本体)，他们把基因的功能分成了三个部分分别是： 细胞组分（cellular component, CC）、分子功能（molecular function, MF） 、 生物过程（biological process, BP） 。利用GO数据库，我们就可以得到我们的目标基因在CC, MF和BP三个层面上，主要和什么有关。 ","date":"2023-07-16","objectID":"/go_kegg%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/:2:1","tags":null,"title":"Go_kegg富集分析","uri":"/go_kegg%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/"},{"categories":["GO\u0026KEGG富集分析"],"content":"KEGG数据库 除了对基因本身功能的注释，我们也知道基因会参与人体的各个通路，基于人体通路而形成的数据库就是通路相关的数据库。 京都基因与基因组百科全书（Kyoto encyclopedia of genes and genomes, KEGG）是系统分析基因功能、基因组信息的数据库，整合了基因组学、生物化学及系统功能组学的信息，有助于研究者把基因及表达信息作为一个整体进行研究。目前KEGG共包含了19个子数据库，富集分析常用在KEGG Pathway通路中。 ","date":"2023-07-16","objectID":"/go_kegg%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/:2:2","tags":null,"title":"Go_kegg富集分析","uri":"/go_kegg%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/"},{"categories":["GO\u0026KEGG富集分析"],"content":"GO_KEGG_GSEA分析 ","date":"2023-07-16","objectID":"/go_kegg%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/:3:0","tags":null,"title":"Go_kegg富集分析","uri":"/go_kegg%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/"},{"categories":["GO\u0026KEGG富集分析"],"content":"下载加载需要的包 下载 install.packages(\"包名称\") 或者 biocManager::install(\"包名称\") BiocManager：是一个 R 包，其中包含了一些用于管理 Bioconductor 包的函数，如 install()、update() 等。使用 :: 表示法，你可以指定调用特定包中的函数。通过 BiocManager，你可以轻松地访问和管理 Bioconductor 存储库中的生物信息学和生物统计学相关的软件包。它简化了安装和维护 Bioconductor 包的过程。 Bioconductor：是一个专门用于生物信息学和生物统计学研究的 R 软件包存储库。它是一个巨大的代码资源库，包含了许多用于基因表达数据分析、基因组学、蛋白质组学等生物学领域的软件包。Bioconductor 提供了丰富的分析工具和算法，能够帮助生物学家处理和解释生物学数据。BiocManager 用于访问和安装 Bioconductor 中的软件包。 :: 不仅可以用于指定调用的包，还可以在不加载整个包的情况下调用该包中的函数。这样可以在特定代码行中临时使用特定包中的函数，而不需要在整个会话中加载该包。:: 只在当前代码行中生效 加载 library(clusterProfiler)#GO\u0026KEGG library(enrichplot)#GO\u0026KEGG library(ggplot2)#柱状图和点状图 library(stringr)#基因ID转换 library(GOplot)#弦图，弦表图，系统聚类图 library(DOSE) library(ggnewscale) library(topGO)#绘制通路网络图 library(circlize)#绘制富集分析圈图 library(ComplexHeatmap)#绘制图例 library(forcats)#绘图中对因子处理 ","date":"2023-07-16","objectID":"/go_kegg%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/:3:1","tags":null,"title":"Go_kegg富集分析","uri":"/go_kegg%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/"},{"categories":["GO\u0026KEGG富集分析"],"content":"读取数据，将基因ID从GENE_SYMBOL转换为ENTREZ_ID #载入数据，只需要基因ID(GO,KEGG,GSEA需要)和log2FOldChange(GSEA(基因集富集分析)需要) data \u003c- read.csv(\"DEG.csv\",header = T) #指定富集分析的物种库 GO_database \u003c- 'org.Hs.eg.db' #GO分析指定物种 KEGG_database \u003c- 'hsa' #KEGG分析指定物种 GO分析指定物种，详见 GO物种缩写索引表 KEGG分析指定物种，详见 keggle物种缩写索引表 #安装注释数据库 if (!require(\"BiocManager\", quietly = TRUE)) install.packages(\"BiocManager\") BiocManager::install(\"org.Hs.eg.db\") 有问题参见官网 Bioconductor - org.Hs.eg.db OrgDb org数据库是一个用于存储特定物种的基因和基因注释信息的数据库。每个org数据库专门用于一个特定的生物物种，例如人类、小鼠、大鼠等。org数据库包含了与该物种相关的基因、基因产物以及它们的注释信息，如基因的功能、组织表达、基因本体注释等。在生物学研究中，研究人员经常需要将基因与GO术语相关联，从而了解基因的功能和参与的生物过程。为此，他们需要使用org数据库中的基因注释信息，将基因与GO术语进行映射，以便进行GO富集分析、基因集对比等功能。 在 http://bioconductor.org/packages/release/BiocViews.html#___OrgDb可以找到对应物种 #gene ID转换 gene \u003c- bitr(data$gene,fromType = 'SYMBOL', toType = 'ENTREZID',OrgDb = GO_database) 如果自己研究的物种不在 http://bioconductor.org/packages/release/BiocViews.html#___OrgDb 之列，很大可能就需要自己构建OrgDb，然后用clusterProfiler分析。非模式生物要想找到自己的注释包，又分成两类： 一类是在 AnnotationHub 中存在的，例如玉米 另一类是在AnnotationHub也不存在相应物种，就需要用 AnnotationForge 来自己构建 若出现 \u003e gene \u003c- bitr(data$gene,fromType = 'SYMBOL', toType = 'ENTREZID',OrgDb = GO_database) 'select()' returned 1:many mapping between keys and columns Warning message: In bitr(data$gene, fromType = \"SYMBOL\", toType = \"ENTREZID\", OrgDb = GO_database) : 0.7% of input gene IDs are fail to map... 一对多映射：某些基因 ID（SYMBOL）可能对应多个基因 ID（ENTREZID）。这种情况通常是因为一个基因可能有多个变体或不同的数据库中存在多个记录。 ","date":"2023-07-16","objectID":"/go_kegg%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/:3:2","tags":null,"title":"Go_kegg富集分析","uri":"/go_kegg%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/"},{"categories":["GO\u0026KEGG富集分析"],"content":"GO分析 #GO分析 GO \u003c- enrichGO(gene$ENTREZID, OrgDb = GO_database, keyType = \"ENTREZID\",#设定读取的gene ID类型 ont = 'ALL', #ont=all即包括GO数据库中的三个部分CC、MF、BP pvalueCutoff = 0.05, qvalueCutoff = 0.05, readable = T) readable 参数用于控制 GO 富集分析结果中的基因 ID 是否转换成易读的描述性名称,即ENTREZ_ID -\u003e SYMBOL_ID,默认为 False ","date":"2023-07-16","objectID":"/go_kegg%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/:3:3","tags":null,"title":"Go_kegg富集分析","uri":"/go_kegg%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/"},{"categories":["GO\u0026KEGG富集分析"],"content":"KEGG分析 （参数和GO差不多） KEGG \u003c- enrichKEGG(gene$ENTREZID,#KEGG富集分析 organism = KEGG_database, pvalueCutoff = 0.05, qvalueCutoff = 0.05) GO \u0026 KEGG 都可以保存为csv文件查看 write.csv(GO,\"./result.csv\") GO_result \u003c- GO@result 所得变量存储格式和输出文件格式相同，可以查看选择感兴趣的定制画图 ","date":"2023-07-16","objectID":"/go_kegg%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/:3:4","tags":null,"title":"Go_kegg富集分析","uri":"/go_kegg%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/"},{"categories":["GO\u0026KEGG富集分析"],"content":"GO \u0026 KEGG结果可视化 ","date":"2023-07-16","objectID":"/go_kegg%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/:4:0","tags":null,"title":"Go_kegg富集分析","uri":"/go_kegg%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/"},{"categories":["GO\u0026KEGG富集分析"],"content":"富集柱状图 + 点状图 barplot(GO, split = \"ONTOLOGY\") + facet_grid(ONTOLOGY~., scale = \"free\") + scale_y_discrete(labels=function(x) str_wrap(x, width = 100)) dotplot(GO, split = \"ONTOLOGY\") + facet_grid(ONTOLOGY~., scale = \"free\") barplot() 函数用于创建柱状图 参数 split = \"ONTOLOGY\" 表示按照 “ONTOLOGY” 列的不同取值（GO_db的三个层面）将数据拆分为不同的柱状图 facet_grid() 函数用于将拆分后的柱状图按照 “ONTOLOGY” 列的不同取值排列在一个网格中。每一行代表一个 “ONTOLOGY” 类别 子图根据数据的分布自动调整高度，即参数 scale = \"free\"，以便更好地展示数据的差异 barplot(GO, showCategory=20) 参数 showCategory 可以控制展示的数量 scale_y_discrete(labels=function(x) str_wrap(x, width = 100)) #调整y轴标签长度，使其放在一行 ","date":"2023-07-16","objectID":"/go_kegg%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/:4:1","tags":null,"title":"Go_kegg富集分析","uri":"/go_kegg%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/"},{"categories":["GO\u0026KEGG富集分析"],"content":"棒棒糖图 ggplot(GO, showCategory = 20, aes(GeneRatio, fct_reorder(Description, GeneRatio))) + geom_segment(aes(xend=0, yend = Description)) + geom_point(aes(color=p.adjust, size = Count)) + scale_color_viridis_c(guide=guide_colorbar(reverse=TRUE)) + scale_size_continuous(range=c(2, 10)) + theme_minimal() + ylab(NULL) aes(GeneRatio, fct_reorder(Description, GeneRatio)): 这里设置了图形的\"美学映射\"（aesthetic mappings） GeneRatio 是x轴的变量，fct_reorder(Description, GeneRatio) 是y轴的变量 fct_reorder() 函数可以根据 GeneRatio 的值对 Description 进行重新排序，这样可以根据 GeneRatio 的大小对y轴的标签进行排列。 ","date":"2023-07-16","objectID":"/go_kegg%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/:4:2","tags":null,"title":"Go_kegg富集分析","uri":"/go_kegg%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/"},{"categories":["GO\u0026KEGG富集分析"],"content":"富集基因与所在功能集/通路集的关联网络图 enrichplot::cnetplot(GO, circular = F, colorEdge = T) circluar为指定是否环化，基因过多建议设置成 F ","date":"2023-07-16","objectID":"/go_kegg%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/:4:3","tags":null,"title":"Go_kegg富集分析","uri":"/go_kegg%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/"},{"categories":["GO\u0026KEGG富集分析"],"content":"富集到的功能集/通路集之间的关联网络图 GO2 \u003c- pairwise_termsim(GO) enrichplot::emapplot(GO2,showCategory = 50, color = \"p.adjust\", layout = \"kk\")#通路间关联网络图 热图展现关联关系 enrichplot::heatplot(GO,showCategory = 50)#基因-通路关联热图 enrichplot::heatplot(KEGG,showCategory = 50) ","date":"2023-07-16","objectID":"/go_kegg%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/:4:4","tags":null,"title":"Go_kegg富集分析","uri":"/go_kegg%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/"},{"categories":["GO\u0026KEGG富集分析"],"content":"GO富集功能网络图 GO_BP\u003c-enrichGO( gene$ENTREZID,#GO富集分析BP模块 OrgDb = GO_database, keyType = \"ENTREZID\", ont = \"BP\", pvalueCutoff = 0.05, pAdjustMethod = \"BH\", qvalueCutoff = 0.05, minGSSize = 10, maxGSSize = 500, readable = T) plotGOgraph(GO_BP)#GO-BP功能网络图 GO_CC\u003c-enrichGO( gene$ENTREZID,#GO富集分析CC模块 OrgDb = GO_database, keyType = \"ENTREZID\", ont = \"CC\", pvalueCutoff = 0.05, pAdjustMethod = \"BH\", qvalueCutoff = 0.05, minGSSize = 10, maxGSSize = 500, readable = T) plotGOgraph(GO_CC)#GO-CC功能网络图 GO_MF\u003c-enrichGO( gene$ENTREZID,#GO富集分析MF模块 OrgDb = GO_database, keyType = \"ENTREZID\", ont = \"MF\", pvalueCutoff = 0.05, pAdjustMethod = \"BH\", qvalueCutoff = 0.05, minGSSize = 10, maxGSSize = 500, readable = T) plotGOgraph(GO_MF)#GO-MF功能网络图 ","date":"2023-07-16","objectID":"/go_kegg%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/:4:5","tags":null,"title":"Go_kegg富集分析","uri":"/go_kegg%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/"},{"categories":["GO\u0026KEGG富集分析"],"content":"GO富集弦图 先要将所有GO富集到的基因集所对应的类型写入本地文件从而得到BP/CC/MF各自的起始位置如我的数据里是1，2103，2410. genedata\u003c-data.frame(ID=info$gene_symbol,logFC=info$log2FoldChange) write.table(GO$ONTOLOGY, file = \"/Users/ZYP/Downloads/KEGG_GO/GO_ONTOLOGYs.txt\", #将所有GO富集到的基因集所对应的类型写入本地文件从而得到BP/CC/MF各自的起始位置如我的数据里是1，2103，2410 append = FALSE, quote = TRUE, sep = \" \", eol = \"\\n\", na = \"NA\", dec = \".\", row.names = TRUE, col.names = TRUE, qmethod = c(\"escape\", \"double\"), fileEncoding = \"\") GOplotIn_BP\u003c-GO[1:10,c(2,3,7,9)] #提取GO富集BP的前10行,提取ID,Description,p.adjust,GeneID四列 GOplotIn_CC\u003c-GO[2103:2112,c(2,3,7,9)]#提取GO富集CC的前10行,提取ID,Description,p.adjust,GeneID四列 GOplotIn_MF\u003c-GO[2410:2419,c(2,3,7,9)]#提取GO富集MF的前10行,提取ID,Description,p.adjust,GeneID四列 GOplotIn_BP$geneID \u003c-str_replace_all(GOplotIn_BP$geneID,'/',',') #把GeneID列中的’/’替换成‘,’ GOplotIn_CC$geneID \u003c-str_replace_all(GOplotIn_CC$geneID,'/',',') GOplotIn_MF$geneID \u003c-str_replace_all(GOplotIn_MF$geneID,'/',',') names(GOplotIn_BP)\u003c-c('ID','Term','adj_pval','Genes')#修改列名,后面弦图绘制的时候需要这样的格式 names(GOplotIn_CC)\u003c-c('ID','Term','adj_pval','Genes') names(GOplotIn_MF)\u003c-c('ID','Term','adj_pval','Genes') GOplotIn_BP$Category = \"BP\"#分类信息 GOplotIn_CC$Category = \"CC\" GOplotIn_MF$Category = \"MF\" circ_BP\u003c-GOplot::circle_dat(GOplotIn_BP,genedata) #GOplot导入数据格式整理 circ_CC\u003c-GOplot::circle_dat(GOplotIn_CC,genedata) circ_MF\u003c-GOplot::circle_dat(GOplotIn_MF,genedata) chord_BP\u003c-chord_dat(data = circ_BP,genes = genedata) #生成含有选定基因的数据框 chord_CC\u003c-chord_dat(data = circ_CC,genes = genedata) chord_MF\u003c-chord_dat(data = circ_MF,genes = genedata) GOChord(data = chord_BP,#弦图 title = 'GO-Biological Process',space = 0.01,#GO Term间距 limit = c(1,1),gene.order = 'logFC',gene.space = 0.25,gene.size = 5, lfc.col = c('red','white','blue'), #上下调基因颜色 process.label = 10) #GO Term字体大小 GOChord(data = chord_CC,title = 'GO-Cellular Component',space = 0.01, limit = c(1,1),gene.order = 'logFC',gene.space = 0.25,gene.size = 5, lfc.col = c('red','white','blue'), process.label = 10) GOChord(data = chord_MF,title = 'GO-Mollecular Function',space = 0.01, limit = c(1,1),gene.order = 'logFC',gene.space = 0.25,gene.size = 5, lfc.col = c('red','white','blue'), process.label = 10) ","date":"2023-07-16","objectID":"/go_kegg%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/:4:6","tags":null,"title":"Go_kegg富集分析","uri":"/go_kegg%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/"},{"categories":["GO\u0026KEGG富集分析"],"content":"参考文章 GO分析和KEGG分析都是啥？ - 知乎 (zhihu.com) 最全的GO, KEGG, GSEA分析教程(R),你要的高端可视化都在这啦！[包含富集圈图] - 知乎 (zhihu.com) ","date":"2023-07-16","objectID":"/go_kegg%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/:5:0","tags":null,"title":"Go_kegg富集分析","uri":"/go_kegg%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90/"},{"categories":null,"content":"自我简介 大家好，我是griedzx，一名大概率喜欢生物信息学的学生，对于生物学和计算机科学的结合产生了浓厚的兴趣，我希望通过写博客来分享我在生物信息学领域的学习心得和经验。 ","date":"2023-06-17","objectID":"/about/:1:0","tags":["about me"],"title":"About","uri":"/about/"},{"categories":null,"content":"学习和技能 生物学基础：我在生物学领域有扎实的基础知识，包括分子生物学、遗传学和生物信息学的基本概念。 编程语言：我熟悉Python编程语言，并且在生物信息学领域中有丰富的编程实践经验。 生物信息学工具：我熟悉常用的生物信息学工具和软件，如BLAST、Bowtie、Samtools等，可以进行基本的序列分析和基因组学研究。 数据分析：我了解常见的数据分析方法和统计学原理，并能够使用相关的工具和库进行生物信息数据的处理和分析。 ","date":"2023-06-17","objectID":"/about/:2:0","tags":["about me"],"title":"About","uri":"/about/"},{"categories":null,"content":"目标 作为一名生物信息专业的学生，我希望在未来能够做出以下贡献： 深入学习和理解生物信息学的前沿技术和方法，如基因组学、转录组学和蛋白质组学等。 运用生物信息学工具和技术解决生物学研究中的实际问题，例如寻找基因突变、预测蛋白质结构等。 参与生物信息学项目，与团队合作并交流学习，推动生物信息学在生命科学研究中的应用。 继续学习和探索相关的计算机科学知识和技术，如机器学习和人工智能在生物信息学中的应用。 ","date":"2023-06-17","objectID":"/about/:3:0","tags":["about me"],"title":"About","uri":"/about/"},{"categories":null,"content":"博客主题 我将在我的博客上分享以下主题： 生物信息学入门指南和基础知识解析。 常用生物信息学工具和软件的介绍和使用技巧。 生物信息学研究方法和数据分析技术的分享。 前沿的生物信息学应用和研究进展的介绍和评论。 生物信息学与其他学科交叉的领域探索，如计算系统生物学和药物设计等。 如果你对以上任何主题感兴趣，欢迎订阅我的博客或在文章下方留言交流。 希望通过我的博客，能够帮助更多的人了解和应用生物信息学，推动生命科学研究的发展。非常感谢你阅读我的第一篇博客文章，期待在未来与你的交流和分享！ ","date":"2023-06-17","objectID":"/about/:4:0","tags":["about me"],"title":"About","uri":"/about/"}]